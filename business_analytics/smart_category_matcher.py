#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ú–ù–´–ô –ü–û–ò–°–ö –¢–û–í–ê–†–û–í –î–õ–Ø –ö–ê–¢–ï–ì–û–†–ò–ô –ò–ó CSV
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""

import sqlite3
import pandas as pd
import numpy as np
from pathlib import Path
from business_final_analyzer import BusinessFinalAnalyzer
import re

class SmartCategoryMatcher:
    def __init__(self, db_path):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        self.keyword_mapping = {
            '–∫–∞—Ä—Ç—Ö–æ–ª–¥–µ—Ä': ['card', 'holder', '–∫–∞—Ä—Ç', '–≤–∏–∑–∏—Ç–∫–∞', '–∫—Ä–µ–¥–∏—Ç–∫–∞', '–ø–ª–∞—Å—Ç–∏–∫'],
            '–∫–∞—Ä–¥—Ö–æ–ª–¥–µ—Ä': ['card', 'holder', '–∫–∞—Ä—Ç', '–≤–∏–∑–∏—Ç–∫–∞', '–∫—Ä–µ–¥–∏—Ç–∫–∞', '–ø–ª–∞—Å—Ç–∏–∫'],
            '—Ä—é–∫–∑–∞–∫': ['backpack', 'bag', '—Å—É–º–∫–∞', '—Å–ø–æ—Ä—Ç', '—à–∫–æ–ª', '—Ç—É—Ä–∏–∑–º'],
            '–ø–æ—è—Å–Ω–∞—è': ['belt', 'waist', '–ø–æ—è—Å', '–±–∞–Ω', '—Å—É–º–∫–∞'],
            '—à–æ–ø–ø–µ—Ä': ['shopping', 'bag', '—Å—É–º–∫–∞', '–ø–æ–∫—É–ø', '—Ç–æ—Ä–≥'],
            '–æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä': ['organizer', '–æ—Ä–≥–∞–Ω–∞–π–∑', '–ø–æ—Ä—è–¥–æ–∫', '—Ö—Ä–∞–Ω–µ–Ω–∏–µ'],
            '–∫–æ—Å–º–µ—Ç–∏—á–∫–∞': ['cosmetic', '–∫–æ—Å–º–µ—Ç–∏–∫', '–º–∞–∫–∏—è–∂', 'beauty'],
            '–ø–µ–Ω–∞–ª': ['pencil', 'case', '–∫–∞–Ω—Ü–µ–ª—è—Ä–∏—è', '—à–∫–æ–ª'],
            '—Ç–µ—Ä–º–æ—Å—É–º–∫–∞': ['thermal', '—Ç–µ—Ä–º–æ', '—Ö–æ–ª–æ–¥', '–∏–∑–æ—Ç–µ—Ä–º'],
            '–∞–≤–æ—Å—å–∫–∞': ['mesh', '—Å–µ—Ç–∫–∞', '—Å—É–º–∫–∞', '–ø—Ä–æ–¥—É–∫—Ç'],
            '—á–µ—Ö–æ–ª': ['case', 'cover', '–∑–∞—â–∏—Ç', 'phone', '—Ç–µ–ª–µ—Ñ–æ–Ω'],
            '—Å—Ç–∏–∫–µ—Ä': ['sticker', '–Ω–∞–∫–ª–µ–π–∫–∞', '—ç—Ç–∏–∫–µ—Ç–∫–∞', 'label'],
            '–Ω–∞–∫–ª–µ–π–∫–∞': ['sticker', '—ç—Ç–∏–∫–µ—Ç–∫–∞', 'label', 'vinyl'],
            '–µ–∂–µ–¥–Ω–µ–≤–Ω–∏–∫': ['diary', 'planner', '–ø–ª–∞–Ω–∏–Ω–≥', 'notebook'],
            '–±–ª–æ–∫–Ω–æ—Ç': ['notebook', 'notepad', '–∑–∞–ø–∏—Å–Ω–∞—è', '—Ç–µ—Ç—Ä–∞–¥—å'],
            '–Ω–æ—Å–∫–∏': ['socks', 'sock', '—á—É–ª–æ—á–Ω–æ', '—Ö–ª–æ–ø–æ–∫'],
            '—à–∞—Ä—Ñ': ['scarf', '–ø–ª–∞—Ç–æ–∫', 'neck', '—à–µ—è'],
            '–ø–ª–∞—Ç–æ–∫': ['scarf', 'handkerchief', '—à–∞—Ä—Ñ', '—à–µ—è'],
            '–∫–µ–ø–∫–∞': ['cap', 'hat', '–±–µ–π—Å–±–æ–ª–∫–∞', '–≥–æ–ª–æ–≤–Ω–æ–π'],
            '–±–µ–π—Å–±–æ–ª–∫–∞': ['cap', 'hat', '–∫–µ–ø–∫–∞', 'baseball'],
            '—Ñ—É—Ç–±–æ–ª–∫–∞': ['t-shirt', 'tshirt', 'shirt', '–º–∞–π–∫–∞'],
            '—Ö—É–¥–∏': ['hoodie', 'sweatshirt', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞', '–∫–∞–ø—é—à–æ–Ω'],
            '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞': ['hoodie', 'sweatshirt', '—Ö—É–¥–∏', '–∫–æ—Ñ—Ç–∞'],
            '—à–∞–ø–∫–∞': ['hat', 'beanie', 'cap', '–≥–æ–ª–æ–≤–Ω–æ–π'],
            '–ø–ª–µ–¥': ['blanket', '–ø–æ–∫—Ä—ã–≤–∞–ª–æ', '–æ–¥–µ—è–ª–æ'],
            '–ø–æ–ª–æ—Ç–µ–Ω—Ü–µ': ['towel', '–±–∞–Ω–Ω–æ–µ', '–º–∞—Ö—Ä–æ–≤–æ–µ'],
            '–ª–∞–Ω—á–±–æ–∫—Å': ['lunch', 'box', '–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä', '–µ–¥–∞'],
            '—Ç–∞–±–ª–µ—Ç–Ω–∏—Ü–∞': ['pill', 'box', '—Ç–∞–±–ª–µ—Ç–∫–∏', '–ª–µ–∫–∞—Ä—Å—Ç–≤–æ'],
            '—Ç–µ—Ä–º–æ—Å': ['thermos', 'thermal', '—Ç–µ—Ä–º–æ'],
            '—Ç–µ—Ä–º–æ–∫—Ä—É–∂–∫–∞': ['thermal', 'mug', '—Ç–µ—Ä–º–æ', '–∫—Ä—É–∂–∫–∞'],
            '—Ç–µ—Ä–º–æ—Å—Ç–∞–∫–∞–Ω': ['thermal', 'cup', '—Ç–µ—Ä–º–æ', '—Å—Ç–∞–∫–∞–Ω'],
            '–±–ª–µ–Ω–¥–µ—Ä': ['blender', '–º–∏–∫—Å–µ—Ä', '–∏–∑–º–µ–ª—å—á–∏—Ç–µ–ª—å'],
            '–≥—Ä–µ–ª–∫–∞': ['warmer', 'heat', '–Ω–∞–≥—Ä–µ–≤–∞—Ç–µ–ª—å'],
            '–º–∞—Å—Å–∞–∂–µ—Ä': ['massage', '–º–∞—Å—Å–∞–∂', '—Ä–µ–ª–∞–∫—Å'],
            '–Ω–∞—É—à–Ω–∏–∫–∏': ['headphone', 'earphone', '–Ω–∞—É—à–Ω–∏–∫'],
            '–ø–∞—É—ç—Ä–±–∞–Ω–∫': ['power', 'bank', '–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä', '–∑–∞—Ä—è–¥–∫–∞'],
            '–ø–æ–≤–µ—Ä–±–∞–Ω–∫': ['power', 'bank', '–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä', '–∑–∞—Ä—è–¥–∫–∞'],
            '–¥–æ–∫—Å—Ç–∞–Ω—Ü–∏—è': ['dock', 'station', '–ø–æ–¥—Å—Ç–∞–≤–∫–∞', '–∑–∞—Ä—è–¥–∫–∞'],
            '—É–≤–ª–∞–∂–Ω–∏—Ç–µ–ª—å': ['humidifier', '—É–≤–ª–∞–∂–Ω', '–≤–æ–∑–¥—É—Ö'],
            '–ø—Ä–æ–µ–∫—Ç–æ—Ä': ['projector', '–ø—Ä–æ–µ–∫—Ü–∏—è', '—ç–∫—Ä–∞–Ω'],
            '—Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫': ['light', 'lamp', '–æ—Å–≤–µ—â–µ–Ω–∏–µ'],
            '–Ω–æ—á–Ω–∏–∫': ['night', 'light', '–¥–µ—Ç—Å–∫–∏–π', '—Å–ø–∞–ª—å–Ω—è'],
            '–∑–Ω–∞—á–æ–∫': ['badge', 'pin', '–∑–Ω–∞–∫', '—ç–º–±–ª–µ–º–∞'],
            '–º–∞–≥–Ω–∏—Ç': ['magnet', '–º–∞–≥–Ω–∏—Ç–Ω—ã–π', '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫'],
            '—Ä–µ–º—É–≤–∫–∞': ['remover', '—Å—Ä–µ–¥—Å—Ç–≤–æ', 'cleaning'],
            '—Ñ–ª–µ—à–∫–∞': ['usb', 'flash', 'drive', '–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å'],
            '—à–Ω—É—Ä–æ–∫': ['cord', 'string', 'lace', '–≤–µ—Ä–µ–≤–∫–∞'],
            '–ª–∞–Ω—å—è—Ä–¥': ['lanyard', '–ª–µ–Ω—Ç–∞', '—à–Ω—É—Ä'],
            '–ø–æ–¥—É—à–∫–∞': ['pillow', 'cushion', '–ø–æ–¥–≥–æ–ª–æ–≤–Ω–∏–∫'],
            '–º–∞—Å–∫–∞': ['mask', '—Å–Ω–∞', '–≥–ª–∞–∑', 'sleep'],
            '–µ–ª–æ—á–Ω–∞—è': ['christmas', '–Ω–æ–≤—ã–π', '–≥–æ–¥', '–ø—Ä–∞–∑–¥–Ω–∏–∫'],
            '–∏–≥—Ä—É—à–∫–∞': ['toy', '–¥–µ—Ç—Å–∫–∞—è', '–∏–≥—Ä–∞'],
            '—Å–Ω–µ–∂–Ω—ã–π': ['snow', 'globe', '—à–∞—Ä'],
            '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä': ['constructor', 'lego', 'building'],
            '–º—è–≥–∫–∞—è': ['soft', '–ø–ª—é—à–µ–≤–∞—è', 'teddy'],
            '–ø–∞–∑–ª': ['puzzle', '–≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞'],
            '–≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞': ['puzzle', 'brain', '–ª–æ–≥–∏–∫–∞'],
            '—à–∞—à–∫–∏': ['checkers', '–∏–≥—Ä–∞', '–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è'],
            '—à–∞—Ö–º–∞—Ç—ã': ['chess', '–∏–≥—Ä–∞', '–Ω–∞—Å—Ç–æ–ª—å–Ω–∞—è'],
            '–∫—Ä—É–≥': ['ring', '–Ω–∞–¥—É–≤–Ω–æ–π', '–ø–ª–∞–≤–∞–Ω–∏–µ'],
            '—Ä–µ–∑–∏–Ω–∫–∞': ['rubber', 'elastic', '—Ñ–∏—Ç–Ω–µ—Å'],
            '—Å–∫–∞–∫–∞–ª–∫–∞': ['rope', 'jump', '–ø—Ä—ã–∂–∫–∏'],
            '–∑–æ–Ω—Ç': ['umbrella', '–¥–æ–∂–¥—å', '–∑–∞—â–∏—Ç–∞'],
            '–∫–æ—Ä–æ–±–∫–∞': ['box', '—É–ø–∞–∫–æ–≤–∫–∞', '–∫–∞—Ä—Ç–æ–Ω'],
            '–∞–≤—Ç–æ–≤–∏–∑–∏—Ç–∫–∞': ['business', 'card', '–≤–∏–∑–∏—Ç–∫–∞'],
            '—Ñ–æ—Ç–æ–∞–ø–ø–∞—Ä–∞—Ç': ['camera', 'photo', '—Ñ–æ—Ç–æ'],
            '—Ç–µ—Ç—Ä–∏—Å': ['tetris', '–∏–≥—Ä–∞', '–≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞'],
            '–∫–∞—Ä–∞–Ω–¥–∞—à': ['pencil', '–∫–∞–Ω—Ü–µ–ª—è—Ä–∏—è', '—Ä–∏—Å–æ–≤–∞–Ω–∏–µ'],
            '–ø–æ–ø—Å–æ–∫–µ—Ç': ['popsocket', 'grip', '–¥–µ—Ä–∂–∞—Ç–µ–ª—å'],
            '–æ–±–ª–æ–∂–∫–∞': ['cover', 'passport', '–¥–æ–∫—É–º–µ–Ω—Ç'],
            '—á–µ–º–æ–¥–∞–Ω': ['suitcase', 'luggage', '–±–∞–≥–∞–∂'],
            '—Å—Ç–∞—Ç—É—ç—Ç–∫–∞': ['figurine', '—Å—Ç–∞—Ç—É—è', '–Ω–∞–≥—Ä–∞–¥–∞'],
            '–Ω–∞–≥—Ä–∞–¥–∞': ['award', 'prize', '—Å—Ç–∞—Ç—É—ç—Ç–∫–∞'],
            '–ø–∞–Ω–∞–º–∞': ['panama', 'hat', '–≥–æ–ª–æ–≤–Ω–æ–π'],
            '–¥–µ—Ä–∂–∞—Ç–µ–ª—å': ['holder', 'stand', '–ø–æ–¥—Å—Ç–∞–≤–∫–∞'],
            '–≥–∏—Ä–ª—è–Ω–¥–∞': ['garland', 'lights', '–æ—Å–≤–µ—â–µ–Ω–∏–µ'],
            '—à–ª–µ–º': ['helmet', '–∑–∞—â–∏—Ç–Ω—ã–π', '–≥–æ–ª–æ–≤–∞']
        }
    
    def get_search_keywords(self, category_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        category_lower = category_name.lower().strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
        parts = re.split(r'[,\-\s]+', category_lower)
        
        keywords = []
        for part in parts:
            part = part.strip()
            if len(part) < 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                continue
                
            keywords.append(part)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
            if part in self.keyword_mapping:
                keywords.extend(self.keyword_mapping[part])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
        keywords = list(set([k for k in keywords if len(k) >= 3]))
        return keywords
    
    def search_products_for_category(self, category_name, limit=100):
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        keywords = self.get_search_keywords(category_name)
        
        if not keywords:
            return pd.DataFrame()
        
        # –°—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ –ø–æ–∏—Å–∫–∞
        search_conditions = []
        
        # 1. –ü–æ–∏—Å–∫ –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Å–ª–æ–≤–∞–º
        for keyword in keywords[:5]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            search_conditions.append(f"(p.title LIKE '%{keyword}%' OR p.original_title LIKE '%{keyword}%')")
        
        # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è–º —Å–ª–æ–≤ (–¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
        if len(keywords) >= 2:
            for i in range(len(keywords)-1):
                search_conditions.append(
                    f"(p.title LIKE '%{keywords[i]}%' AND p.title LIKE '%{keywords[i+1]}%')"
                )
        
        where_clause = ' OR '.join(search_conditions)
        
        query = f"""
        SELECT 
            p.id,
            p.original_title,
            p.title,
            pv.price_cny,
            pv.price_rub, 
            pv.price_usd,
            pv.moq,
            pv.item_weight,
            pv.transport_tariff,
            pv.cargo_density,
            pv.quantity_in_box
        FROM products p
        JOIN product_variants pv ON p.id = pv.product_id
        WHERE ({where_clause})
            AND pv.moq > 1
            AND p.title NOT LIKE '%sample%'
            AND p.title NOT LIKE '%–æ–±—Ä–∞–∑–µ—Ü%'
            AND p.title NOT LIKE '%logo%'
            AND p.title NOT LIKE '%–ª–æ–≥–æ—Ç–∏–ø%'
        ORDER BY pv.price_rub DESC
        LIMIT {limit}
        """
        
        try:
            df_found = pd.read_sql_query(query, self.conn)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            if len(df_found) > 0:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                df_found['relevance_score'] = 0
                
                for keyword in keywords:
                    mask_title = df_found['title'].str.contains(keyword, case=False, na=False)
                    mask_original = df_found['original_title'].str.contains(keyword, case=False, na=False)
                    df_found.loc[mask_title | mask_original, 'relevance_score'] += 1
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                df_found = df_found.sort_values('relevance_score', ascending=False)
                df_found = df_found.head(50)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 50 –ª—É—á—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                
            return df_found
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è '{category_name}': {e}")
            return pd.DataFrame()
    
    def calculate_ranges_for_products(self, products_df):
        """–†–∞—Å—á–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        if len(products_df) < 3:
            return {}
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã (–∏—Å–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–∑—Ü—ã)
        products_only = products_df[products_df['moq'] > 1].copy()
        
        if len(products_only) < 3:
            return {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç–Ω—ã–µ –ø–æ–ª—è
        products_only.loc[:, 'avg_requested_tirage'] = products_only['moq'] * 2
        
        ranges = {}
        metrics = {
            'price_rub': '–¶–µ–Ω–∞ (‚ÇΩ)',
            'price_cny': '–¶–µ–Ω–∞ (¬•)', 
            'avg_requested_tirage': '–¢–∏—Ä–∞–∂',
            'cargo_density': '–ü–ª–æ—Ç–Ω–æ—Å—Ç—å',
            'transport_tariff': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç ($)'
        }
        
        for field, label in metrics.items():
            data = products_only[field].copy()
            
            # –£–±–∏—Ä–∞–µ–º NaN
            data = data.dropna()
            
            # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–∏ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
            data = data[data > 0]
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            if field == 'cargo_density':
                data = data[data >= 10.0]
            elif field == 'transport_tariff':
                data = data[data >= 0.1]
            elif field == 'price_rub':
                data = data[data >= 1]
            elif field == 'price_cny':
                data = data[data >= 0.1]
            elif field == 'avg_requested_tirage':
                data = data[data >= 10]
            
            if len(data) >= 3:
                percentile_15 = data.quantile(0.15)
                percentile_85 = data.quantile(0.85)
                
                ranges[field] = {
                    'label': label,
                    'mean': data.mean(),
                    'std': data.std(),
                    'lower_70': percentile_15,
                    'upper_70': percentile_85,
                    'min': data.min(),
                    'max': data.max(),
                    'median': data.median(),
                    'count': len(data)
                }
        
        return ranges
    
    def enhance_csv_categories(self):
        """–ü–æ–∏—Å–∫ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ CSV"""
        
        print("üîç –£–ú–ù–´–ô –ü–û–ò–°–ö –¢–û–í–ê–†–û–í –î–õ–Ø –ö–ê–¢–ï–ì–û–†–ò–ô –ò–ó CSV")
        print("=" * 60)
        
        # –ß–∏—Ç–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–ª—å–∫–æ –∏–∑ CSV
        csv_only = pd.read_excel('COMPREHENSIVE_DATA_ANALYSIS.xlsx', sheet_name='üü†_–¢–æ–ª—å–∫–æ_CSV')
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(csv_only)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–ª—å–∫–æ –∏–∑ CSV")
        
        enhanced_categories = []
        successful_matches = 0
        
        for i, row in csv_only.iterrows():
            category_name = row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']
            print(f"\nüîç –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è '{category_name}'...")
            
            # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã
            products_df = self.search_products_for_category(category_name)
            
            if len(products_df) >= 5:  # –ú–∏–Ω–∏–º—É–º 5 —Ç–æ–≤–∞—Ä–æ–≤
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(products_df)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã
                ranges = self.calculate_ranges_for_products(products_df)
                
                # –°–æ–∑–¥–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                enhanced_row = row.copy()
                enhanced_row['–¢–æ–≤–∞—Ä–æ–≤'] = len(products_df)
                enhanced_row['–ü–æ–ª–Ω–æ—Ç–∞_–¥–∞–Ω–Ω—ã—Ö'] = "üü¢ –ü–û–õ–ù–´–ï –î–ê–ù–ù–´–ï"
                enhanced_row['–ï—Å—Ç—å_–¥–∏–∞–ø–∞–∑–æ–Ω—ã_–ë–î'] = True
                enhanced_row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤'] = len(ranges)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ–¥–∏–∞–Ω—ã
                enhanced_row['–ú–µ–¥–∏–∞–Ω–∞_—Ü–µ–Ω—ã_—Ä—É–±'] = products_df['price_rub'].median() if not products_df['price_rub'].isna().all() else None
                enhanced_row['–ú–µ–¥–∏–∞–Ω–∞_—Ü–µ–Ω—ã_—é–∞–Ω—å'] = products_df['price_cny'].median() if not products_df['price_cny'].isna().all() else None
                enhanced_row['–ú–µ–¥–∏–∞–Ω–∞_—Ç–∏—Ä–∞–∂–∞'] = products_df['moq'].median() if not products_df['moq'].isna().all() else None
                enhanced_row['–ú–µ–¥–∏–∞–Ω–∞_–ø–ª–æ—Ç–Ω–æ—Å—Ç–∏'] = products_df['cargo_density'].median() if not products_df['cargo_density'].isna().all() else None
                enhanced_row['–ú–µ–¥–∏–∞–Ω–∞_—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞'] = products_df['transport_tariff'].median() if not products_df['transport_tariff'].isna().all() else None
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã
                for field, data in ranges.items():
                    if field == 'price_rub':
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_–º–∏–Ω'] = data['lower_70']
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_–º–∞–∫—Å'] = data['upper_70']
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_–º–µ–¥–∏–∞–Ω–∞'] = data['median']
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_—Å—Ä–µ–¥–Ω–µ–µ'] = data['mean']
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_—Å—Ç–¥'] = data['std']
                        enhanced_row['–¶–µ–Ω–∞_—Ä—É–±_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = data['count']
                    elif field == 'price_cny':
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_–º–∏–Ω'] = data['lower_70']
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_–º–∞–∫—Å'] = data['upper_70']
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_–º–µ–¥–∏–∞–Ω–∞'] = data['median']
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_—Å—Ä–µ–¥–Ω–µ–µ'] = data['mean']
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_—Å—Ç–¥'] = data['std']
                        enhanced_row['–¶–µ–Ω–∞_—é–∞–Ω—å_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = data['count']
                    elif field == 'avg_requested_tirage':
                        enhanced_row['–¢–∏—Ä–∞–∂_–º–∏–Ω'] = data['lower_70']
                        enhanced_row['–¢–∏—Ä–∞–∂_–º–∞–∫—Å'] = data['upper_70']
                        enhanced_row['–¢–∏—Ä–∞–∂_–º–µ–¥–∏–∞–Ω–∞'] = data['median']
                        enhanced_row['–¢–∏—Ä–∞–∂_—Å—Ä–µ–¥–Ω–µ–µ'] = data['mean']
                        enhanced_row['–¢–∏—Ä–∞–∂_—Å—Ç–¥'] = data['std']
                        enhanced_row['–¢–∏—Ä–∞–∂_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = data['count']
                    elif field == 'cargo_density':
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_–º–∏–Ω'] = data['lower_70']
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_–º–∞–∫—Å'] = data['upper_70']
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_–º–µ–¥–∏–∞–Ω–∞'] = data['median']
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_—Å—Ä–µ–¥–Ω–µ–µ'] = data['mean']
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_—Å—Ç–¥'] = data['std']
                        enhanced_row['–ü–ª–æ—Ç–Ω–æ—Å—Ç—å_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = data['count']
                    elif field == 'transport_tariff':
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_–º–∏–Ω'] = data['lower_70']
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_–º–∞–∫—Å'] = data['upper_70']
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_–º–µ–¥–∏–∞–Ω–∞'] = data['median']
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_—Å—Ä–µ–¥–Ω–µ–µ'] = data['mean']
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_—Å—Ç–¥'] = data['std']
                        enhanced_row['–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç_–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = data['count']
                
                enhanced_categories.append(enhanced_row)
                successful_matches += 1
                
            else:
                print(f"  ‚ùå –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(products_df)} —Ç–æ–≤–∞—Ä–æ–≤ (–º–∏–Ω–∏–º—É–º 5)")
        
        print(f"\nüéâ –†–ï–ó–£–õ–¨–¢–ê–¢: {successful_matches} –∏–∑ {len(csv_only)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π —É—Å–ø–µ—à–Ω–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–æ")
        
        if successful_matches > 0:
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            df_enhanced = pd.DataFrame(enhanced_categories)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output_file = Path(__file__).parent / "ENHANCED_CSV_CATEGORIES.xlsx"
            
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                df_enhanced.to_excel(writer, sheet_name='–î–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ_–∫–∞—Ç–µ–≥–æ—Ä–∏–∏', index=False)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
                success_stats = pd.DataFrame([{
                    '–í—Å–µ–≥–æ_–∫–∞—Ç–µ–≥–æ—Ä–∏–π_CSV': len(csv_only),
                    '–£—Å–ø–µ—à–Ω–æ_–¥–æ–ø–æ–ª–Ω–µ–Ω–æ': successful_matches,
                    '–ü—Ä–æ—Ü–µ–Ω—Ç_—É—Å–ø–µ—Ö–∞': (successful_matches / len(csv_only)) * 100,
                    '–¢–æ–≤–∞—Ä–æ–≤_–¥–æ–±–∞–≤–ª–µ–Ω–æ': df_enhanced['–¢–æ–≤–∞—Ä–æ–≤'].sum(),
                    '–°—Ä–µ–¥–Ω–µ_—Ç–æ–≤–∞—Ä–æ–≤': df_enhanced['–¢–æ–≤–∞—Ä–æ–≤'].mean()
                }])
                success_stats.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞_–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è', index=False)
            
            print(f"‚úÖ –î–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
            return df_enhanced
        
        return pd.DataFrame()
    
    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

def main():
    db_path = Path(__file__).parent.parent / "promo_calculator" / "database" / "advanced_merged_products_clean.db"
    
    matcher = SmartCategoryMatcher(db_path)
    enhanced_df = matcher.enhance_csv_categories()
    
    return enhanced_df

if __name__ == "__main__":
    main()
