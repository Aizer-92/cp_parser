#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ OTAPI API
"""
import json
import time
from pathlib import Path
from datetime import datetime
from otapi_parser import OTAPIParser

def get_items_to_parse():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª —Å –æ—Å—Ç–∞–≤—à–∏–º–∏—Å—è —Ç–æ–≤–∞—Ä–∞–º–∏
        remaining_file = Path("data/results/remaining_items.json")
        if remaining_file.exists():
            with open(remaining_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list) and len(data) > 0:
                print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(data)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
                return data[:500]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 500
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–∞, –±–µ—Ä–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ë–î
        print("üìã –§–∞–π–ª remaining_items.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –±–µ—Ä–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ë–î")
        return get_items_without_images_from_db()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
        return []

def get_items_without_images_from_db():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ë–î"""
    try:
        import sqlite3
        
        db_path = Path("data/results/all_chunks_database.db")
        if not db_path.exists():
            print("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return []
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        cursor.execute('''
            SELECT p.item_id 
            FROM products p 
            WHERE NOT EXISTS (SELECT 1 FROM images i WHERE i.item_id = p.item_id)
            LIMIT 500
        ''')
        
        items = [row[0] for row in cursor.fetchall()]
        conn.close()
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ë–î")
        return items
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –ë–î: {e}")
        return []

def save_chunk(results, chunk_number):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç chunk —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
        chunks_dir = Path("data/results/chunks")
        chunks_dir.mkdir(parents=True, exist_ok=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"otapi_chunk_{chunk_number:03d}_{timestamp}.json"
        filepath = chunks_dir / filename
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Chunk —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
        return filepath
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è chunk: {e}")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ú–ê–°–°–û–í–´–ô –ü–ê–†–°–ò–ù–ì –¢–û–í–ê–†–û–í –ß–ï–†–ï–ó OTAPI API")
    print("=" * 60)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    items_to_parse = get_items_to_parse()
    
    if not items_to_parse:
        print("‚ùå –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞!")
        return
    
    print(f"üéØ –¶–ï–õ–¨: –ü–∞—Ä—Å–∏–Ω–≥ {len(items_to_parse)} —Ç–æ–≤–∞—Ä–æ–≤")
    print(f"üìä –ü–µ—Ä–≤—ã–µ 5 —Ç–æ–≤–∞—Ä–æ–≤: {items_to_parse[:5]}")
    print()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = OTAPIParser()
    
    # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã
    start_time = time.time()
    results = parser.parse_batch(items_to_parse)
    end_time = time.time()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    parsing_time = end_time - start_time
    avg_time_per_item = parsing_time / len(items_to_parse) if items_to_parse else 0
    
    print(f"\n‚è±Ô∏è  –í–†–ï–ú–Ø –ü–ê–†–°–ò–ù–ì–ê:")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {parsing_time:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ–≤–∞—Ä: {avg_time_per_item:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {len(results)/parsing_time:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
    
    if results:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ chunk
        chunk_file = save_chunk(results, 1)
        
        if chunk_file:
            print(f"\n‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
            print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {chunk_file.name}")
            print(f"üìä –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(results)} —Ç–æ–≤–∞—Ä–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            analyze_results_quality(results)
        else:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
    else:
        print(f"\n‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")

def analyze_results_quality(results):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    print("-" * 40)
    
    if not results:
        return
    
    total_items = len(results)
    items_with_title = 0
    items_with_description = 0
    items_with_images = 0
    items_with_attributes = 0
    items_with_physical = 0
    items_with_weight = 0
    
    for item in results:
        raw_data = item.get('raw_data', {})
        item_data = raw_data.get('Item', {})
        
        if item_data.get('Title'):
            items_with_title += 1
        
        if item_data.get('Description'):
            items_with_description += 1
        
        if item_data.get('Pictures'):
            items_with_images += 1
        
        if item_data.get('Attributes'):
            items_with_attributes += 1
        
        if item_data.get('PhysicalParameters'):
            items_with_physical += 1
        
        if item_data.get('ActualWeightInfo'):
            items_with_weight += 1
    
    print(f"üìä –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   –ó–∞–≥–æ–ª–æ–≤–∫–∏: {items_with_title}/{total_items} ({items_with_title/total_items*100:.1f}%)")
    print(f"   –û–ø–∏—Å–∞–Ω–∏—è: {items_with_description}/{total_items} ({items_with_description/total_items*100:.1f}%)")
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {items_with_images}/{total_items} ({items_with_images/total_items*100:.1f}%)")
    print(f"   –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {items_with_attributes}/{total_items} ({items_with_attributes/total_items*100:.1f}%)")
    print(f"   –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {items_with_physical}/{total_items} ({items_with_physical/total_items*100:.1f}%)")
    print(f"   –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–µ: {items_with_weight}/{total_items} ({items_with_weight/total_items*100:.1f}%)")

if __name__ == "__main__":
    main()
