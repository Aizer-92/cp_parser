#!/usr/bin/env python3
"""
–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ–ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤
"""
import sqlite3
import json
import time
import threading
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from otapi_parser import OTAPIParser
import queue

class MultithreadedParser:
    """–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä"""
    
    def __init__(self, max_workers=8):
        self.max_workers = max_workers
        self.results = []
        self.errors = 0
        self.lock = threading.Lock()
        self.progress_queue = queue.Queue()
        
    def parse_missing_data_multithreaded(self):
        """–ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–º —Ä–µ–∂–∏–º–µ"""
        print(f"üöÄ –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–´–ô –ü–ê–†–°–ò–ù–ì –¢–û–í–ê–†–û–í (–ø–æ—Ç–æ–∫–æ–≤: {self.max_workers})")
        print("=" * 60)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        db_path = Path("data/results/all_chunks_database.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π –ò–õ–ò –±–µ–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        cursor.execute('''
            SELECT DISTINCT p.item_id, p.title, p.chunk_source, p.chunk_type
            FROM products p
            WHERE (p.description IS NULL OR p.description = '' OR p.description = '–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞')
               OR NOT EXISTS (SELECT 1 FROM specifications s WHERE s.item_id = p.item_id)
            ORDER BY p.item_id
            LIMIT 2000
        ''')
        
        items = cursor.fetchall()
        conn.close()
        
        if not items:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –¥–æ–ø–∞—Ä—Å–∏–Ω–≥–∞!")
            return
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –¥–æ–ø–∞—Ä—Å–∏–Ω–≥–∞")
        print(f"üìä –ü–µ—Ä–≤—ã–µ 5: {[item[0] for item in items[:5]]}")
        print()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
            future_to_item = {
                executor.submit(self.parse_single_item, item): item 
                for item in items
            }
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            completed = 0
            for future in as_completed(future_to_item):
                item = future_to_item[future]
                completed += 1
                
                try:
                    result = future.result()
                    if result:
                        with self.lock:
                            self.results.append(result)
                    else:
                        with self.lock:
                            self.errors += 1
                except Exception as e:
                    with self.lock:
                        self.errors += 1
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {item[0]}: {e}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if completed % 100 == 0:
                    success_rate = len(self.results) / completed * 100
                    print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {completed}/{len(items)} ({completed/len(items)*100:.1f}%)")
                    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(self.results)}")
                    print(f"   ‚ùå –û—à–∏–±–æ–∫: {self.errors}")
                    print(f"   üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
                    print()
        
        end_time = time.time()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        parsing_time = end_time - start_time
        success_rate = len(self.results) / len(items) * 100 if items else 0
        
        print(f"\n‚è±Ô∏è  –í–†–ï–ú–Ø –ü–ê–†–°–ò–ù–ì–ê:")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {parsing_time:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ–≤–∞—Ä: {parsing_time/len(items):.1f} —Å–µ–∫—É–Ω–¥")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {len(self.results)/parsing_time:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
        print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {len(items)/parsing_time:.2f}x (vs 0.26 —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫ –≤ –æ–¥–Ω–æ–ø–æ—Ç–æ—á–Ω–æ–º)")
        
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(items)}")
        print(f"   –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(self.results)}")
        print(f"   –û—à–∏–±–æ–∫: {self.errors}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        
        if self.results:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            self.analyze_data_quality()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ chunk
            chunk_file = self.save_chunk(4)
            
            if chunk_file:
                print(f"\n‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
                print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {chunk_file.name}")
                print(f"üìä –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(self.results)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ
                self.show_next_steps()
            else:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
        else:
            print(f"\n‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
    
    def parse_single_item(self, item):
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä"""
        item_id, title, chunk_source, chunk_type = item
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            parser = OTAPIParser()
            
            # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä —á–µ—Ä–µ–∑ OTAPI
            result = parser.parse_product(item_id)
            
            if result:
                raw_data = result.get('raw_data', {})
                item_data = raw_data.get('Item', {})
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏
                description = item_data.get('Description', '')
                attributes = item_data.get('Attributes', [])
                physical = item_data.get('PhysicalParameters', {})
                weight_info = item_data.get('ActualWeightInfo', {})
                pictures = item_data.get('Pictures', [])
                main_image = item_data.get('MainPictureUrl', '')
                
                has_description = bool(description and description.strip())
                has_attributes = bool(attributes and len(attributes) > 0)
                has_physical = bool(physical and len(physical) > 0)
                has_weight = bool(weight_info and len(weight_info) > 0)
                has_images = bool((pictures and len(pictures) > 0) or main_image)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                parsed_item = {
                    'id': f'abb-{item_id}',
                    'item_id': item_id,
                    'url': f'https://detail.1688.com/offer/{item_id}.html',
                    'title': title,
                    'status': 'success',
                    'raw_data': {
                        'Item': item_data
                    }
                }
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –æ—á–µ—Ä–µ–¥–∏
                self.progress_queue.put({
                    'item_id': item_id,
                    'has_description': has_description,
                    'has_attributes': has_attributes,
                    'description_length': len(description),
                    'attributes_count': len(attributes)
                })
                
                return parsed_item
            else:
                return None
                
        except Exception as e:
            return None
    
    def analyze_data_quality(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•:")
        print("-" * 40)
        
        if not self.results:
            return
        
        total_items = len(self.results)
        items_with_description = 0
        items_with_attributes = 0
        items_with_physical = 0
        items_with_weight = 0
        items_with_images = 0
        
        total_attributes = 0
        total_physical_params = 0
        total_weight_params = 0
        total_images = 0
        total_description_length = 0
        
        for item in self.results:
            raw_data = item.get('raw_data', {})
            item_data = raw_data.get('Item', {})
            
            # –û–ø–∏—Å–∞–Ω–∏—è
            description = item_data.get('Description', '')
            if description and description.strip():
                items_with_description += 1
                total_description_length += len(description)
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            attributes = item_data.get('Attributes', [])
            if attributes and len(attributes) > 0:
                items_with_attributes += 1
                total_attributes += len(attributes)
            
            # –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            physical = item_data.get('PhysicalParameters', {})
            if physical and len(physical) > 0:
                items_with_physical += 1
                total_physical_params += len(physical)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–µ
            weight_info = item_data.get('ActualWeightInfo', {})
            if weight_info and len(weight_info) > 0:
                items_with_weight += 1
                total_weight_params += len(weight_info)
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            pictures = item_data.get('Pictures', [])
            main_image = item_data.get('MainPictureUrl', '')
            if (pictures and len(pictures) > 0) or main_image:
                items_with_images += 1
                total_images += len(pictures) + (1 if main_image else 0)
        
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏—è: {items_with_description}/{total_items} ({items_with_description/total_items*100:.1f}%)")
        if items_with_description > 0:
            avg_desc_length = total_description_length / items_with_description
            print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_desc_length:.1f} —Å–∏–º–≤–æ–ª–æ–≤")
        
        print(f"üìã –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {items_with_attributes}/{total_items} ({items_with_attributes/total_items*100:.1f}%)")
        if items_with_attributes > 0:
            avg_attrs = total_attributes / items_with_attributes
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_attrs:.1f} —à—Ç")
        
        print(f"üìè –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {items_with_physical}/{total_items} ({items_with_physical/total_items*100:.1f}%)")
        if items_with_physical > 0:
            avg_physical = total_physical_params / items_with_physical
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_physical:.1f} —à—Ç")
        
        print(f"‚öñÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–µ: {items_with_weight}/{total_items} ({items_with_weight/total_items*100:.1f}%)")
        if items_with_weight > 0:
            avg_weight = total_weight_params / items_with_weight
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_weight:.1f} —à—Ç")
        
        print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {items_with_images}/{total_items} ({items_with_images/total_items*100:.1f}%)")
        if items_with_images > 0:
            avg_images = total_images / items_with_images
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_images:.1f} —à—Ç")
    
    def save_chunk(self, chunk_number):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç chunk —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
            chunks_dir = Path("data/results/chunks")
            chunks_dir.mkdir(parents=True, exist_ok=True)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"otapi_chunk_{chunk_number:03d}_{timestamp}.json"
            filepath = chunks_dir / filename
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ Chunk —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è chunk: {e}")
            return None
    
    def show_next_steps(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ"""
        print(f"\nüéØ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print(f"   1. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–æ–≤—ã–π chunk –≤ –ë–î")
        print(f"   2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        print(f"   3. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
        print(f"   4. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ–π –ë–î")
        
        print(f"\nüí° –ö–û–ú–ê–ù–î–´ –î–õ–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print(f"   # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å chunk –≤ –ë–î:")
        print(f"   python3 merge_otapi_chunk.py")
        print(f"   ")
        print(f"   # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î:")
        print(f"   python3 check_final_database.py")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä —Å 8 –ø–æ—Ç–æ–∫–∞–º–∏
    parser = MultithreadedParser(max_workers=8)
    parser.parse_missing_data_multithreaded()

if __name__ == "__main__":
    main()
