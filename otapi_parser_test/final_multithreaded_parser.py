#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ—Ö –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤
"""
import sqlite3
import json
import time
import threading
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from otapi_parser import OTAPIParser
import queue

class FinalMultithreadedParser:
    """–§–∏–Ω–∞–ª—å–Ω—ã–π –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å 10 –ø–æ—Ç–æ–∫–∞–º–∏"""
    
    def __init__(self, max_workers=10):
        self.max_workers = max_workers
        self.results = []
        self.errors = 0
        self.lock = threading.Lock()
        self.progress_queue = queue.Queue()
        
    def parse_all_remaining_data(self):
        """–ü–∞—Ä—Å–∏—Ç –í–°–ï –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        print(f"üöÄ –§–ò–ù–ê–õ–¨–ù–´–ô –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–´–ô –ü–ê–†–°–ò–ù–ì (–ø–æ—Ç–æ–∫–æ–≤: {self.max_workers})")
        print("=" * 60)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        db_path = Path("data/results/all_chunks_database.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π –ò–õ–ò –±–µ–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        cursor.execute('''
            SELECT DISTINCT p.item_id, p.title, p.chunk_source, p.chunk_type
            FROM products p
            WHERE (p.description IS NULL OR p.description = '' OR p.description = '–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞')
               OR NOT EXISTS (SELECT 1 FROM specifications s WHERE s.item_id = p.item_id)
            ORDER BY p.item_id
        ''')
        
        items = cursor.fetchall()
        conn.close()
        
        if not items:
            print("üéâ –í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –∏–º–µ—é—Ç –æ–ø–∏—Å–∞–Ω–∏—è –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏!")
            return
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–æ–ø–∞—Ä—Å–∏–Ω–≥–∞")
        print(f"üìä –ü–µ—Ä–≤—ã–µ 5: {[item[0] for item in items[:5]]}")
        print()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏ –ø–æ 1000 —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
        batch_size = 1000
        total_batches = (len(items) + batch_size - 1) // batch_size
        
        print(f"üì¶ –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ {total_batches} –±–∞—Ç—á–µ–π –ø–æ {batch_size} —Ç–æ–≤–∞—Ä–æ–≤")
        print()
        
        all_results = []
        total_errors = 0
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(items))
            batch_items = items[start_idx:end_idx]
            
            print(f"üîÑ –ë–ê–¢–ß {batch_num + 1}/{total_batches} ({len(batch_items)} —Ç–æ–≤–∞—Ä–æ–≤)")
            print("-" * 40)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –±–∞—Ç—á–∞
            batch_results, batch_errors = self.parse_batch(batch_items)
            
            all_results.extend(batch_results)
            total_errors += batch_errors
            
            print(f"‚úÖ –ë–∞—Ç—á {batch_num + 1} –∑–∞–≤–µ—Ä—à–µ–Ω:")
            print(f"   –£—Å–ø–µ—à–Ω–æ: {len(batch_results)}")
            print(f"   –û—à–∏–±–æ–∫: {batch_errors}")
            print(f"   –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {len(all_results)}/{len(items)} ({len(all_results)/len(items)*100:.1f}%)")
            print()
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
            if batch_num < total_batches - 1:
                print("‚è≥ –ü–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏...")
                time.sleep(5)
                print()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        success_rate = len(all_results) / len(items) * 100 if items else 0
        
        print(f"üéØ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(items)}")
        print(f"   –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_results)}")
        print(f"   –û—à–∏–±–æ–∫: {total_errors}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        
        if all_results:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            self.analyze_data_quality(all_results)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ chunk
            chunk_file = self.save_chunk(all_results, 5)
            
            if chunk_file:
                print(f"\n‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
                print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {chunk_file.name}")
                print(f"üìä –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_results)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ
                self.show_next_steps()
            else:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
        else:
            print(f"\n‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
    
    def parse_batch(self, items):
        """–ü–∞—Ä—Å–∏—Ç –±–∞—Ç—á —Ç–æ–≤–∞—Ä–æ–≤"""
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
            future_to_item = {
                executor.submit(self.parse_single_item, item): item 
                for item in items
            }
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            batch_results = []
            batch_errors = 0
            completed = 0
            
            for future in as_completed(future_to_item):
                item = future_to_item[future]
                completed += 1
                
                try:
                    result = future.result()
                    if result:
                        batch_results.append(result)
                    else:
                        batch_errors += 1
                except Exception as e:
                    batch_errors += 1
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 —Ç–æ–≤–∞—Ä–æ–≤
                if completed % 100 == 0:
                    success_rate = len(batch_results) / completed * 100
                    print(f"   üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {completed}/{len(items)} ({completed/len(items)*100:.1f}%)")
                    print(f"      ‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(batch_results)}")
                    print(f"      ‚ùå –û—à–∏–±–æ–∫: {batch_errors}")
                    print(f"      üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        
        end_time = time.time()
        parsing_time = end_time - start_time
        
        print(f"   ‚è±Ô∏è –í—Ä–µ–º—è –±–∞—Ç—á–∞: {parsing_time:.1f} —Å–µ–∫")
        print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {len(batch_results)/parsing_time:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
        
        return batch_results, batch_errors
    
    def parse_single_item(self, item):
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä"""
        item_id, title, chunk_source, chunk_type = item
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            parser = OTAPIParser()
            
            # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä —á–µ—Ä–µ–∑ OTAPI
            result = parser.parse_product(item_id)
            
            if result:
                raw_data = result.get('raw_data', {})
                item_data = raw_data.get('Item', {})
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏
                description = item_data.get('Description', '')
                attributes = item_data.get('Attributes', [])
                physical = item_data.get('PhysicalParameters', {})
                weight_info = item_data.get('ActualWeightInfo', {})
                pictures = item_data.get('Pictures', [])
                main_image = item_data.get('MainPictureUrl', '')
                
                has_description = bool(description and description.strip())
                has_attributes = bool(attributes and len(attributes) > 0)
                has_physical = bool(physical and len(physical) > 0)
                has_weight = bool(weight_info and len(weight_info) > 0)
                has_images = bool((pictures and len(pictures) > 0) or main_image)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                parsed_item = {
                    'id': f'abb-{item_id}',
                    'item_id': item_id,
                    'url': f'https://detail.1688.com/offer/{item_id}.html',
                    'title': title,
                    'status': 'success',
                    'raw_data': {
                        'Item': item_data
                    }
                }
                
                return parsed_item
            else:
                return None
                
        except Exception as e:
            return None
    
    def analyze_data_quality(self, results):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•:")
        print("-" * 40)
        
        if not results:
            return
        
        total_items = len(results)
        items_with_description = 0
        items_with_attributes = 0
        items_with_physical = 0
        items_with_weight = 0
        items_with_images = 0
        
        total_attributes = 0
        total_physical_params = 0
        total_weight_params = 0
        total_images = 0
        total_description_length = 0
        
        for item in results:
            raw_data = item.get('raw_data', {})
            item_data = raw_data.get('Item', {})
            
            # –û–ø–∏—Å–∞–Ω–∏—è
            description = item_data.get('Description', '')
            if description and description.strip():
                items_with_description += 1
                total_description_length += len(description)
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            attributes = item_data.get('Attributes', [])
            if attributes and len(attributes) > 0:
                items_with_attributes += 1
                total_attributes += len(attributes)
            
            # –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            physical = item_data.get('PhysicalParameters', {})
            if physical and len(physical) > 0:
                items_with_physical += 1
                total_physical_params += len(physical)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–µ
            weight_info = item_data.get('ActualWeightInfo', {})
            if weight_info and len(weight_info) > 0:
                items_with_weight += 1
                total_weight_params += len(weight_info)
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            pictures = item_data.get('Pictures', [])
            main_image = item_data.get('MainPictureUrl', '')
            if (pictures and len(pictures) > 0) or main_image:
                items_with_images += 1
                total_images += len(pictures) + (1 if main_image else 0)
        
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏—è: {items_with_description}/{total_items} ({items_with_description/total_items*100:.1f}%)")
        if items_with_description > 0:
            avg_desc_length = total_description_length / items_with_description
            print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_desc_length:.1f} —Å–∏–º–≤–æ–ª–æ–≤")
        
        print(f"üìã –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {items_with_attributes}/{total_items} ({items_with_attributes/total_items*100:.1f}%)")
        if items_with_attributes > 0:
            avg_attrs = total_attributes / items_with_attributes
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_attrs:.1f} —à—Ç")
        
        print(f"üìè –§–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {items_with_physical}/{total_items} ({items_with_physical/total_items*100:.1f}%)")
        if items_with_physical > 0:
            avg_physical = total_physical_params / items_with_physical
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_physical:.1f} —à—Ç")
        
        print(f"‚öñÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Å–µ: {items_with_weight}/{total_items} ({items_with_weight/total_items*100:.1f}%)")
        if items_with_weight > 0:
            avg_weight = total_weight_params / items_with_weight
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_weight:.1f} —à—Ç")
        
        print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {items_with_images}/{total_items} ({items_with_images/total_items*100:.1f}%)")
        if items_with_images > 0:
            avg_images = total_images / items_with_images
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {avg_images:.1f} —à—Ç")
    
    def save_chunk(self, results, chunk_number):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç chunk —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
            chunks_dir = Path("data/results/chunks")
            chunks_dir.mkdir(parents=True, exist_ok=True)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"otapi_chunk_{chunk_number:03d}_{timestamp}.json"
            filepath = chunks_dir / filename
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ Chunk —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è chunk: {e}")
            return None
    
    def show_next_steps(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ"""
        print(f"\nüéØ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print(f"   1. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π chunk –≤ –ë–î")
        print(f"   2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        print(f"   3. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ–π –ë–î")
        print(f"   4. –°–æ–∑–¥–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç")
        
        print(f"\nüí° –ö–û–ú–ê–ù–î–´ –î–õ–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
        print(f"   # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å chunk –≤ –ë–î:")
        print(f"   python3 merge_otapi_chunk.py")
        print(f"   ")
        print(f"   # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î:")
        print(f"   python3 check_final_database.py")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä —Å 10 –ø–æ—Ç–æ–∫–∞–º–∏
    parser = FinalMultithreadedParser(max_workers=10)
    parser.parse_all_remaining_data()

if __name__ == "__main__":
    main()
