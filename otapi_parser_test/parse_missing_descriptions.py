#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π
"""
import sqlite3
import json
import time
from pathlib import Path
from datetime import datetime
from otapi_parser import OTAPIParser

def parse_missing_descriptions():
    """–ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π"""
    print("üöÄ –ú–ê–°–°–û–í–´–ô –ü–ê–†–°–ò–ù–ì –¢–û–í–ê–†–û–í –ë–ï–ó –û–ü–ò–°–ê–ù–ò–ô")
    print("=" * 60)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    db_path = Path("data/results/all_chunks_database.db")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π
    cursor.execute('''
        SELECT item_id, title, chunk_source, chunk_type
        FROM products
        WHERE description IS NULL OR description = '' OR description = '–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞'
        ORDER BY item_id
        LIMIT 1000
    ''')
    
    items = cursor.fetchall()
    conn.close()
    
    if not items:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π!")
        return
    
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π")
    print(f"üìä –ü–µ—Ä–≤—ã–µ 5: {[item[0] for item in items[:5]]}")
    print()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = OTAPIParser()
    
    # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã
    start_time = time.time()
    results = []
    errors = 0
    
    for i, (item_id, title, chunk_source, chunk_type) in enumerate(items, 1):
        try:
            print(f"üîç [{i}/{len(items)}] –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞ {item_id}...")
            
            # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä —á–µ—Ä–µ–∑ OTAPI
            result = parser.parse_product(item_id)
            
            if result:
                raw_data = result.get('raw_data', {})
                item_data = raw_data.get('Item', {})
                
                description = item_data.get('Description', '')
                has_description = bool(description and description.strip())
                
                if has_description:
                    print(f"    ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                    results.append({
                        'item_id': item_id,
                        'title': title,
                        'description': description,
                        'chunk_source': chunk_source,
                        'chunk_type': chunk_type
                    })
                else:
                    print(f"    ‚ùå –û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ API")
                    errors += 1
            else:
                print(f"    ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
                errors += 1
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(items):
                time.sleep(0.5)
                
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
            errors += 1
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 —Ç–æ–≤–∞—Ä–æ–≤
        if i % 50 == 0:
            print(f"\nüìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(items)} ({i/len(items)*100:.1f}%)")
            print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(results)}")
            print(f"   ‚ùå –û—à–∏–±–æ–∫: {errors}")
            print()
    
    end_time = time.time()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    parsing_time = end_time - start_time
    success_rate = len(results) / len(items) * 100 if items else 0
    
    print(f"\n‚è±Ô∏è  –í–†–ï–ú–Ø –ü–ê–†–°–ò–ù–ì–ê:")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {parsing_time:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ç–æ–≤–∞—Ä: {parsing_time/len(items):.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {len(results)/parsing_time:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(items)}")
    print(f"   –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(results)}")
    print(f"   –û—à–∏–±–æ–∫: {errors}")
    print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
    
    if results:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ chunk
        chunk_file = save_chunk(results, 3)
        
        if chunk_file:
            print(f"\n‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
            print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {chunk_file.name}")
            print(f"üìä –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(results)} —Ç–æ–≤–∞—Ä–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ
            show_next_steps()
        else:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
    else:
        print(f"\n‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")

def save_chunk(results, chunk_number):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç chunk —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
        chunks_dir = Path("data/results/chunks")
        chunks_dir.mkdir(parents=True, exist_ok=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"otapi_chunk_{chunk_number:03d}_{timestamp}.json"
        filepath = chunks_dir / filename
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Chunk —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
        return filepath
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è chunk: {e}")
        return None

def show_next_steps():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ"""
    print(f"\nüéØ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
    print(f"   1. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–æ–≤—ã–π chunk –≤ –ë–î")
    print(f"   2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
    print(f"   3. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
    print(f"   4. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ–π –ë–î")
    
    print(f"\nüí° –ö–û–ú–ê–ù–î–´ –î–õ–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:")
    print(f"   # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å chunk –≤ –ë–î:")
    print(f"   python3 merge_otapi_chunk.py")
    print(f"   ")
    print(f"   # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î:")
    print(f"   python3 check_final_database.py")

if __name__ == "__main__":
    parse_missing_descriptions()
