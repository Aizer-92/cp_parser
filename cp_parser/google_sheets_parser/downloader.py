#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Google Sheets Downloader - —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
"""

import os
import sys
import requests
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse, parse_qs
import json
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(str(Path(__file__).parent.parent))

class GoogleSheetsDownloader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Google Sheets –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel"""
    
    def __init__(self, output_dir: str = "production_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logger
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_attempts': 0,
            'successful_downloads': 0,
            'failed_downloads': 0,
            'skipped_existing': 0,
            'errors': []
        }
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # –¢–∞–π–º–∞—É—Ç—ã (—Å–æ–∫—Ä–∞—â–µ–Ω—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∑–∞–≤–∏—Å–∞–Ω–∏–π)
        self.download_timeout = 15  # –°–æ–∫—Ä–∞—â–µ–Ω —Å 30 –¥–æ 15 —Å–µ–∫—É–Ω–¥
        self.retry_delay = 1       # –°–æ–∫—Ä–∞—â–µ–Ω —Å 2 –¥–æ 1 —Å–µ–∫—É–Ω–¥—ã
        self.max_retries = 2       # –°–æ–∫—Ä–∞—â–µ–Ω —Å 3 –¥–æ 2 –ø–æ–ø—ã—Ç–æ–∫
    
    def extract_sheet_id(self, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Google Sheets URL"""
        try:
            if 'docs.google.com/spreadsheets' not in url:
                return None
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω: /spreadsheets/d/{SHEET_ID}/
            import re
            pattern = r'/spreadsheets/d/([a-zA-Z0-9-_]+)'
            match = re.search(pattern, url)
            return match.group(1) if match else None
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è Sheet ID –∏–∑ {url}: {e}")
            return None
    
    def build_export_url(self, sheet_id: str, format: str = 'xlsx') -> str:
        """–°–æ–∑–¥–∞–µ—Ç URL –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ Google Sheets"""
        return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format={format}"
    
    def download_sheet_direct(self, sheet_id: str, filename: str) -> bool:
        """–ü—Ä—è–º–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ export URL"""
        
        export_url = self.build_export_url(sheet_id, 'xlsx')
        output_path = self.output_dir / filename
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ñ–∞–π–ª
        if output_path.exists():
            self.logger.info(f"‚è≠Ô∏è  –§–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {filename}")
            self.stats['skipped_existing'] += 1
            return True
        
        try:
            self.logger.info(f"‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞—é: {filename}")
            
            response = requests.get(
                export_url, 
                headers=self.headers, 
                timeout=(5, self.download_timeout),  # (connect_timeout, read_timeout)
                stream=True
            )
            
            if response.status_code == 200:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º content-type
                content_type = response.headers.get('content-type', '')
                if 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' in content_type or 'application/zip' in content_type:
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
                    with open(output_path, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                    
                    file_size = output_path.stat().st_size
                    self.logger.info(f"‚úÖ –°–∫–∞—á–∞–Ω: {filename} ({file_size} –±–∞–π—Ç)")
                    self.stats['successful_downloads'] += 1
                    return True
                else:
                    self.logger.warning(f"‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π content-type: {content_type}")
                    return False
            
            elif response.status_code == 403:
                self.logger.error(f"‚ùå –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): {filename}")
                return False
            
            elif response.status_code == 404:
                self.logger.error(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (404): {filename}")  
                return False
            
            else:
                self.logger.error(f"‚ùå HTTP {response.status_code}: {filename}")
                return False
                
        except requests.exceptions.Timeout:
            self.logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {filename}")
            return False
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {filename}: {e}")
            return False
    
    def download_with_retries(self, sheet_id: str, filename: str) -> bool:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        
        for attempt in range(1, self.max_retries + 1):
            try:
                if self.download_sheet_direct(sheet_id, filename):
                    return True
                
                if attempt < self.max_retries:
                    self.logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä {attempt + 1}/{self.max_retries} –¥–ª—è {filename}")
                    time.sleep(self.retry_delay * attempt)
                    
            except Exception as e:
                self.logger.error(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {filename}: {e}")
                if attempt < self.max_retries:
                    time.sleep(self.retry_delay * attempt)
        
        self.stats['failed_downloads'] += 1
        self.stats['errors'].append({
            'filename': filename,
            'sheet_id': sheet_id,
            'error': '–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ —É–¥–∞–ª–∏—Å—å'
        })
        return False
    
    def download_batch(self, sheets_data: List[Dict], batch_size: int = 20, start_from: int = 0) -> Dict:
        """–ë–∞—Ç—á–µ–≤–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        
        total_sheets = len(sheets_data)
        end_at = min(start_from + batch_size, total_sheets)
        
        self.logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –±–∞—Ç—á–∞: —Ç–∞–±–ª–∏—Ü—ã {start_from + 1}-{end_at} –∏–∑ {total_sheets}")
        
        batch_data = sheets_data[start_from:end_at]
        
        for i, sheet_info in enumerate(batch_data, start_from + 1):
            self.logger.info(f"\\nüìã {i}/{total_sheets}: {sheet_info['filename']}")
            
            self.stats['total_attempts'] += 1
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
            success = self.download_with_retries(
                sheet_info['sheet_id'], 
                sheet_info['filename']
            )
            
            if not success:
                self.logger.error(f"‚ùå –ù–µ—É–¥–∞—á–∞: {sheet_info['filename']}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è–º–∏
            if i < end_at:
                time.sleep(0.5)
        
        return self.get_batch_stats()
    
    def get_batch_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞"""
        return {
            'total_attempts': self.stats['total_attempts'],
            'successful_downloads': self.stats['successful_downloads'],
            'failed_downloads': self.stats['failed_downloads'],
            'skipped_existing': self.stats['skipped_existing'],
            'success_rate': (self.stats['successful_downloads'] / self.stats['total_attempts'] * 100) if self.stats['total_attempts'] > 0 else 0,
            'errors_count': len(self.stats['errors'])
        }
    
    def save_errors_report(self, filename: str = "download_errors.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö"""
        
        if not self.stats['errors']:
            return
        
        errors_file = self.output_dir / filename
        
        try:
            with open(errors_file, 'w', encoding='utf-8') as f:
                json.dump(self.stats['errors'], f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"üìÑ –û—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {errors_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
    
    def print_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        
        stats = self.get_batch_stats()
        
        print(f"\\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {stats['successful_downloads']}")
        print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –µ—Å—Ç—å): {stats['skipped_existing']}")
        print(f"‚ùå –ù–µ—É–¥–∞—á–∏: {stats['failed_downloads']}")
        print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats['success_rate']:.1f}%")
        print(f"üìÅ –ü–∞–ø–∫–∞ —Å —Ñ–∞–π–ª–∞–º–∏: {self.output_dir.absolute()}")
        
        if self.stats['errors']:
            print(f"‚ö†Ô∏è  –û—à–∏–±–æ–∫: {len(self.stats['errors'])}")
            self.save_errors_report()

def main():
    """–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞"""
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º CSV –ø–∞—Ä—Å–µ—Ä
    from csv_parser import CSVMasterTableParser
    
    # –ü–∞—Ä—Å–∏–º CSV
    csv_path = Path(__file__).parent.parent.parent / "–ö–æ–ø–∏–ª–∫–∞ –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π - –ü—Ä–æ—Å—á–µ—Ç—ã .csv"
    
    if not csv_path.exists():
        print(f"‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
        return
    
    try:
        # –ü–∞—Ä—Å–∏–º CSV
        csv_parser = CSVMasterTableParser(str(csv_path))
        sheets_data = csv_parser.parse_csv_file()
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(sheets_data)} Google Sheets —Ç–∞–±–ª–∏—Ü")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫
        downloader = GoogleSheetsDownloader()
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ç–∞–±–ª–∏—Ü –¥–ª—è —Ç–µ—Å—Ç–∞
        print(f"\\nüß™ –¢–ï–°–¢–û–í–û–ï –°–ö–ê–ß–ò–í–ê–ù–ò–ï (–ø–µ—Ä–≤—ã–µ 5 —Ç–∞–±–ª–∏—Ü):")
        stats = downloader.download_batch(sheets_data, batch_size=5, start_from=0)
        
        downloader.print_summary()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise

if __name__ == "__main__":
    main()

