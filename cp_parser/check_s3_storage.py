#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ S3/FTP –Ω–∞ Beget
–ê–Ω–∞–ª–∏–∑: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–æ–≤
"""

from ftplib import FTP_TLS
import time
from datetime import datetime
from collections import defaultdict

# FTP –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
FTP_HOST = "ftp.ru1.storage.beget.cloud"
FTP_USER = "RECD00AQJIM4300MLJ0W"
FTP_PASS = "FIucJ3i9iIWZ5ieJvabvI0OxEn2Yv4gG5XRUeSNf"
FTP_DIR = "/73d16f7545b3-promogoods/images"

def get_size_readable(bytes_size):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.2f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.2f} PB"

def analyze_storage():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ FTP"""
    print("="*80)
    print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ê–õ–¨–ù–û–ì–û –•–†–ê–ù–ò–õ–ò–©–ê –ù–ê BEGET S3/FTP")
    print("="*80)
    
    print(f"\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ FTP...")
    print(f"   Host: {FTP_HOST}")
    print(f"   Path: {FTP_DIR}")
    
    try:
        ftp = FTP_TLS(FTP_HOST)
        ftp.login(FTP_USER, FTP_PASS)
        ftp.prot_p()
        ftp.cwd(FTP_DIR)
        print("   ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ\n")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return
    
    print("üì• –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)...")
    start_time = time.time()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
    files_data = []
    try:
        # LIST –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞:
        # -rw-r--r--   1 user group    1234567 Oct 12 14:23 filename.png
        lines = []
        ftp.retrlines('LIST', lines.append)
        
        for line in lines:
            parts = line.split()
            if len(parts) >= 9:
                # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ - —ç—Ç–æ –æ–±—ã—á–Ω–æ 5-–π —ç–ª–µ–º–µ–Ω—Ç
                try:
                    size = int(parts[4])
                    filename = ' '.join(parts[8:])  # –∏–º—è —Ñ–∞–π–ª–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã
                    files_data.append({
                        'name': filename,
                        'size': size
                    })
                except (ValueError, IndexError):
                    continue
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}")
        ftp.quit()
        return
    
    elapsed = time.time() - start_time
    print(f"‚úÖ –°–ø–∏—Å–æ–∫ –ø–æ–ª—É—á–µ–Ω –∑–∞ {elapsed:.1f} —Å–µ–∫\n")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    ftp.quit()
    
    # –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•
    print("="*80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)
    
    total_files = len(files_data)
    total_size = sum(f['size'] for f in files_data)
    
    print(f"\nüìÅ –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files:,}")
    print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {get_size_readable(total_size)}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {get_size_readable(total_size / total_files if total_files > 0 else 0)}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º
    print(f"\nüì∑ –§–û–†–ú–ê–¢–´ –§–ê–ô–õ–û–í:")
    formats = defaultdict(lambda: {'count': 0, 'size': 0})
    
    for f in files_data:
        ext = f['name'].split('.')[-1].lower() if '.' in f['name'] else 'no_ext'
        formats[ext]['count'] += 1
        formats[ext]['size'] += f['size']
    
    for ext in sorted(formats.keys(), key=lambda x: formats[x]['size'], reverse=True):
        count = formats[ext]['count']
        size = formats[ext]['size']
        percent = (size / total_size * 100) if total_size > 0 else 0
        avg = size / count if count > 0 else 0
        print(f"   .{ext:6s}: {count:6,} —Ñ–∞–π–ª–æ–≤ | {get_size_readable(size):>10} ({percent:5.1f}%) | avg: {get_size_readable(avg)}")
    
    # –¢–û–ü —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    print(f"\nüîù –¢–û–ü-20 –°–ê–ú–´–• –ë–û–õ–¨–®–ò–• –§–ê–ô–õ–û–í:")
    sorted_files = sorted(files_data, key=lambda x: x['size'], reverse=True)
    
    for i, f in enumerate(sorted_files[:20], 1):
        size_mb = f['size'] / (1024 * 1024)
        name = f['name'][:60] + '...' if len(f['name']) > 60 else f['name']
        print(f"   {i:2d}. {get_size_readable(f['size']):>10} - {name}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º
    print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –†–ê–ó–ú–ï–†–ê–ú:")
    size_ranges = {
        '–û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ (<100 KB)': (0, 100 * 1024),
        '–ú–∞–ª–µ–Ω—å–∫–∏–µ (100 KB - 500 KB)': (100 * 1024, 500 * 1024),
        '–°—Ä–µ–¥–Ω–∏–µ (500 KB - 1 MB)': (500 * 1024, 1 * 1024 * 1024),
        '–ë–æ–ª—å—à–∏–µ (1 MB - 5 MB)': (1 * 1024 * 1024, 5 * 1024 * 1024),
        '–û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ (5 MB - 10 MB)': (5 * 1024 * 1024, 10 * 1024 * 1024),
        '–û–≥—Ä–æ–º–Ω—ã–µ (>10 MB)': (10 * 1024 * 1024, float('inf'))
    }
    
    for label, (min_size, max_size) in size_ranges.items():
        files_in_range = [f for f in files_data if min_size <= f['size'] < max_size]
        count = len(files_in_range)
        size = sum(f['size'] for f in files_in_range)
        percent = (count / total_files * 100) if total_files > 0 else 0
        size_percent = (size / total_size * 100) if total_size > 0 else 0
        print(f"   {label:30s}: {count:6,} ({percent:5.1f}%) | {get_size_readable(size):>10} ({size_percent:5.1f}%)")
    
    # –ü–û–¢–ï–ù–¶–ò–ê–õ –°–ñ–ê–¢–ò–Ø
    print(f"\nüí° –ü–û–¢–ï–ù–¶–ò–ê–õ –°–ñ–ê–¢–ò–Ø:")
    
    # –§–∞–π–ª—ã >1 MB –º–æ–∂–Ω–æ —Ö–æ—Ä–æ—à–æ —Å–∂–∞—Ç—å
    large_files = [f for f in files_data if f['size'] > 1 * 1024 * 1024]
    large_size = sum(f['size'] for f in large_files)
    
    # –û—Ü–µ–Ω–∫–∞: WebP –¥–∞–µ—Ç ~90% —Å–∂–∞—Ç–∏—è –¥–ª—è PNG
    estimated_after = large_size * 0.1  # 10% –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
    estimated_savings = large_size - estimated_after
    
    print(f"   –§–∞–π–ª–æ–≤ >1 MB: {len(large_files):,}")
    print(f"   –ò—Ö —Ä–∞–∑–º–µ—Ä: {get_size_readable(large_size)}")
    print(f"   –ü–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è (WebP): {get_size_readable(estimated_after)}")
    print(f"   üí∞ –≠–∫–æ–Ω–æ–º–∏—è: {get_size_readable(estimated_savings)} ({(estimated_savings/large_size*100):.1f}%)")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    report_file = f"STORAGE_ANALYSIS_{timestamp}.txt"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"–ê–Ω–∞–ª–∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ Beget S3/FTP\n")
        f.write(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"="*80 + "\n\n")
        
        f.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files:,}\n")
        f.write(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {get_size_readable(total_size)}\n\n")
        
        f.write("–í–°–ï –§–ê–ô–õ–´ (–æ—Ç –±–æ–ª—å—à–∏—Ö –∫ –º–µ–Ω—å—à–∏–º):\n")
        f.write("-"*80 + "\n")
        for i, file in enumerate(sorted_files, 1):
            f.write(f"{i:5d}. {get_size_readable(file['size']):>10} - {file['name']}\n")
    
    print(f"\n‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
    print("="*80)

if __name__ == '__main__':
    analyze_storage()



