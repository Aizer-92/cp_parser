#!/usr/bin/env python3
"""
–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –¥—É–±–ª–µ–π —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º –ø–æ–∑–∏—Ü–∏–π
"""

import re
import csv
from collections import defaultdict

def extract_filenames_and_sizes_from_report(report_file):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏ –∏—Ö —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –æ—Ç—á–µ—Ç–∞"""
    files_data = []
    
    with open(report_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            match = re.search(r'(\d+\.\d+)\s+(KB|MB|GB)\s+-\s+(.+)$', line)
            if match:
                size_value = float(match.group(1))
                size_unit = match.group(2)
                filename = match.group(3).strip()
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ KB
                if size_unit == 'MB':
                    size_kb = size_value * 1024
                elif size_unit == 'GB':
                    size_kb = size_value * 1024 * 1024
                else:
                    size_kb = size_value
                
                files_data.append({
                    'filename': filename,
                    'size_kb': size_kb
                })
    
    return files_data


def parse_filename_correct(filename):
    """
    –ü–†–ê–í–ò–õ–¨–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥:
    –§–æ—Ä–º–∞—Ç: {sheet_id}_{position}_{hash}.png
    –∏–ª–∏: {sheet_id}_{position}_{suffix}_{hash}.png
    
    –ü–æ–∑–∏—Ü–∏—è - —ç—Ç–æ –ü–û–°–õ–ï–î–ù–Ø–Ø —á–∞—Å—Ç—å –ø–µ—Ä–µ–¥ —Ö–µ—à–µ–º, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É [A-Z]+\d+
    
    –ü—Ä–∏–º–µ—Ä—ã:
    1. 1fwvX9lN3tRlhmI_X0Ie9b-W1wX8B-2sh-vDSfc9NdbY_O4_04a64599.png
       sheet_id: 1fwvX9lN3tRlhmI_X0Ie9b-W1wX8B-2sh-vDSfc9NdbY
       position: O4
       hash: 04a64599
    
    2. 1tadByKcZFWoLp05vV_TqaPslPdZVi-_ofiSBmF6_GR0_O13_74e0eac4.png
       sheet_id: 1tadByKcZFWoLp05vV_TqaPslPdZVi-_ofiSBmF6_GR0 (–≤–∫–ª—é—á–∞—è GR0!)
       position: O13
       hash: 74e0eac4
       
    3. 16t27DZ6EnQVx7DeHN9F1GKr4Ae9o5KL9luBS_rQ8WKg_Q8_3_62b0f70c.png
       sheet_id: 16t27DZ6EnQVx7DeHN9F1GKr4Ae9o5KL9luBS_rQ8WKg
       position: Q8
       suffix: 3
       hash: 62b0f70c
    """
    
    if not filename.endswith('.png') and not filename.endswith('.pn') and not filename.endswith('.p'):
        return None
    
    if '...' in filename:
        return None
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = filename.replace('.png', '').replace('.pn', '').replace('.p', '')
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—é
    parts = name.split('_')
    
    if len(parts) < 3:
        return None
    
    # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é —Å –ö–û–ù–¶–ê
    # –ü–æ–∑–∏—Ü–∏—è - —ç—Ç–æ [A-Z]+\d+
    position_pattern = r'^[A-Z]+\d+$'
    
    position_idx = None
    for i in range(len(parts) - 1, 0, -1):  # –∏–¥–µ–º —Å –∫–æ–Ω—Ü–∞, –Ω–æ –Ω–µ –≤–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if re.match(position_pattern, parts[i]):
            position_idx = i
            break
    
    if position_idx is None:
        return None
    
    result = {
        'filename': filename,
        'sheet_id': '_'.join(parts[:position_idx]),
        'position': parts[position_idx],
        'suffix': None
    }
    
    # –í—Å–µ —á—Ç–æ –ø–æ—Å–ª–µ –ø–æ–∑–∏—Ü–∏–∏ - —ç—Ç–æ —Å—É—Ñ—Ñ–∏–∫—Å –∏/–∏–ª–∏ —Ö–µ—à
    remaining = parts[position_idx + 1:]
    
    if len(remaining) >= 2:
        # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∏ —Ü–∏—Ñ—Ä–æ–≤–æ–π - —ç—Ç–æ —Å—É—Ñ—Ñ–∏–∫—Å
        if len(remaining[0]) <= 3 and remaining[0].isdigit():
            result['suffix'] = remaining[0]
    
    return result


def main():
    print("=" * 80)
    print("üîç –ü–†–ê–í–ò–õ–¨–ù–´–ô –ü–û–ò–°–ö –î–£–ë–õ–ï–ô –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("=" * 80)
    print()
    
    report_file = 'STORAGE_ANALYSIS_20251012_1455.txt'
    
    print(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {report_file}")
    files_data = extract_filenames_and_sizes_from_report(report_file)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(files_data):,} —Ñ–∞–π–ª–æ–≤")
    
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞...")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ sheet_id + position + suffix
    groups = defaultdict(list)
    failed_parse = 0
    
    for i, file_data in enumerate(files_data, 1):
        if i % 5000 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,} / {len(files_data):,} ({i/len(files_data)*100:.1f}%)")
        
        filename = file_data['filename']
        size_kb = file_data['size_kb']
        
        if '...' in filename:
            continue
        
        parsed = parse_filename_correct(filename)
        
        if parsed:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á: sheet_id + position + suffix
            key = f"{parsed['sheet_id']}|{parsed['position']}|{parsed['suffix'] or ''}"
            
            groups[key].append({
                'filename': filename,
                'size_kb': size_kb,
                'sheet_id': parsed['sheet_id'],
                'position': parsed['position'],
                'suffix': parsed['suffix'] or ''
            })
        else:
            failed_parse += 1
    
    print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–æ –≥—Ä—É–ø–ø: {len(groups):,}")
    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {failed_parse:,}")
    
    # –ò—â–µ–º –¥—É–±–ª–∏ - –≥—Ä—É–ø–ø—ã —Å –±–æ–ª–µ–µ —á–µ–º 1 —Ñ–∞–π–ª–æ–º
    print("\nüîç –ü–æ–∏—Å–∫ –¥—É–±–ª–µ–π...")
    
    duplicates = []
    duplicate_groups = []
    
    for key, files in groups.items():
        if len(files) > 1:
            duplicate_groups.append({
                'key': key,
                'files': files,
                'count': len(files)
            })
            duplicates.extend(files)
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø —Å –¥—É–±–ª—è–º–∏: {len(duplicate_groups):,}")
    print(f"‚úÖ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–µ–π: {len(duplicates):,}")
    
    if not duplicate_groups:
        print("\nüéâ –î—É–±–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ! –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã.")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥—É–±–ª–µ–π
    duplicate_groups.sort(key=lambda x: x['count'], reverse=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    detail_file = 'REAL_DUPLICATES_DETAIL.csv'
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {detail_file}")
    
    with open(detail_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['sheet_id', 'position', 'suffix', 'filename', 'size_kb', 'size_mb', 'image_url'])
        
        for group in duplicate_groups:
            parts = group['key'].split('|')
            sheet_id = parts[0]
            position = parts[1]
            suffix = parts[2]
            
            for file_data in group['files']:
                url = f"https://ftp.ru1.storage.beget.cloud/73d16f7545b3-promogoods/images/{file_data['filename']}"
                writer.writerow([
                    sheet_id,
                    position,
                    suffix,
                    file_data['filename'],
                    f"{file_data['size_kb']:.2f}",
                    f"{file_data['size_kb']/1024:.2f}",
                    url
                ])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É –ø–æ –≥—Ä—É–ø–ø–∞–º
    summary_file = 'REAL_DUPLICATES_SUMMARY.csv'
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å–≤–æ–¥–∫—É: {summary_file}")
    
    with open(summary_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['sheet_id', 'position', 'suffix', 'duplicate_count', 'total_size_mb', 'sizes_mb', 'same_size'])
        
        for group in duplicate_groups:
            parts = group['key'].split('|')
            sheet_id = parts[0]
            position = parts[1]
            suffix = parts[2]
            
            total_size = sum(f['size_kb'] for f in group['files'])
            sizes = [f"{f['size_kb']/1024:.2f}" for f in group['files']]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –ª–∏ —Ä–∞–∑–º–µ—Ä (—Å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å—é 1%)
            size_values = [f['size_kb'] for f in group['files']]
            avg_size = sum(size_values) / len(size_values)
            same_size = all(abs(s - avg_size) / avg_size < 0.01 for s in size_values)
            
            writer.writerow([
                sheet_id,
                position,
                suffix,
                group['count'],
                f"{total_size/1024:.2f}",
                ' | '.join(sizes),
                '–î–ê' if same_size else '–ù–ï–¢'
            ])
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–£–ë–õ–ï–ô")
    print("=" * 80)
    
    total_duplicate_size = sum(f['size_kb'] for f in duplicates) / 1024  # –≤ MB
    
    print(f"\nüìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
    print(f"   –ì—Ä—É–ø–ø —Å –¥—É–±–ª—è–º–∏: {len(duplicate_groups):,}")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–µ–π: {len(duplicates):,}")
    print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥—É–±–ª–µ–π: {total_duplicate_size:.2f} MB ({total_duplicate_size/1024:.2f} GB)")
    
    # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è
    files_to_delete = len(duplicates) - len(duplicate_groups)
    size_to_free = sum(
        sum(f['size_kb'] for f in group['files'][1:]) 
        for group in duplicate_groups
    ) / 1024
    
    print(f"\nüíæ –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–ê–Ø –≠–ö–û–ù–û–ú–ò–Ø (—É–¥–∞–ª–∏–≤ –¥—É–±–ª–∏):")
    print(f"   –§–∞–π–ª–æ–≤ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å: {files_to_delete:,}")
    print(f"   –ú–µ—Å—Ç–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç—Å—è: {size_to_free:.2f} MB ({size_to_free/1024:.2f} GB)")
    
    # –î—É–±–ª–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
    same_size_groups = [g for g in duplicate_groups if all(
        abs(f['size_kb'] - g['files'][0]['size_kb']) / g['files'][0]['size_kb'] < 0.01
        for f in g['files']
    )]
    
    print(f"\nüîç –î–£–ë–õ–ò –° –û–î–ò–ù–ê–ö–û–í–´–ú –†–ê–ó–ú–ï–†–û–ú (—Ç–æ—á–Ω—ã–µ –∫–æ–ø–∏–∏):")
    print(f"   –ì—Ä—É–ø–ø: {len(same_size_groups):,}")
    print(f"   –§–∞–π–ª–æ–≤: {sum(len(g['files']) for g in same_size_groups):,}")
    
    # –¢–û–ü-10 –≥—Ä—É–ø–ø —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥—É–±–ª–µ–π
    print(f"\nüîù –¢–û–ü-10 –ì–†–£–ü–ü –° –ù–ê–ò–ë–û–õ–¨–®–ò–ú –ö–û–õ–ò–ß–ï–°–¢–í–û–ú –î–£–ë–õ–ï–ô:")
    for i, group in enumerate(duplicate_groups[:10], 1):
        parts = group['key'].split('|')
        sheet_id = parts[0][:40]
        position = parts[1]
        suffix = parts[2] or '(–Ω–µ—Ç)'
        total_size = sum(f['size_kb'] for f in group['files']) / 1024
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä
        size_values = [f['size_kb'] for f in group['files']]
        avg_size = sum(size_values) / len(size_values)
        same_size = all(abs(s - avg_size) / avg_size < 0.01 for s in size_values)
        same_size_label = "‚úÖ –û–î–ò–ù–ê–ö–û–í–´–ô" if same_size else "‚ùå —Ä–∞–∑–Ω—ã–π"
        
        print(f"   {i:2d}. Sheet: {sheet_id:40s} | Pos: {position:4s} | Suf: {suffix:3s} | "
              f"–î—É–±–ª–µ–π: {group['count']:2d} | {total_size:.1f} MB | {same_size_label}")
    
    # –ü—Ä–∏–º–µ—Ä –≥—Ä—É–ø–ø—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
    if same_size_groups:
        print(f"\nüìã –ü–†–ò–ú–ï–† –¢–û–ß–ù–´–• –î–£–ë–õ–ï–ô (–ø–µ—Ä–≤–∞—è –≥—Ä—É–ø–ø–∞ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º):")
        first_group = same_size_groups[0]
        parts = first_group['key'].split('|')
        print(f"   Sheet ID: {parts[0]}")
        print(f"   Position: {parts[1]}")
        print(f"   Suffix: {parts[2] or '(–Ω–µ—Ç)'}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {first_group['count']}")
        print(f"\n   –§–∞–π–ª—ã:")
        for j, file_data in enumerate(first_group['files'], 1):
            print(f"      {j}. {file_data['filename'][:70]:70s} - {file_data['size_kb']/1024:.2f} MB")
    
    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 80)
    print(f"\nüìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {detail_file}")
    print(f"üìÑ –°–≤–æ–¥–∫–∞: {summary_file}")
    print(f"\nüí° –î—É–±–ª–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º - —ç—Ç–æ –¢–û–ß–ù–´–ï –ö–û–ü–ò–ò, –∏—Ö –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ —É–¥–∞–ª–∏—Ç—å")


if __name__ == '__main__':
    main()

