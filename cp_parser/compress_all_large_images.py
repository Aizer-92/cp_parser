#!/usr/bin/env python3
"""
–ú–∞—Å—Å–æ–≤–æ–µ —Å–∂–∞—Ç–∏–µ –≤—Å–µ—Ö –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (>1MB) –Ω–∞ S3
–°–æ–∑–¥–∞—ë—Ç WebP –≤–µ—Ä—Å–∏–∏, –æ–±–Ω–æ–≤–ª—è–µ—Ç –ë–î, –æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—ã –∫–∞–∫ backup
"""
import sys
import os
from pathlib import Path
import requests
from io import BytesIO
from PIL import Image
import boto3
from botocore.client import Config
from datetime import datetime
import time

sys.path.insert(0, str(Path.cwd()))
from database.postgresql_manager import PostgreSQLManager
from sqlalchemy import text

# S3 credentials (Beget Cloud Storage)
S3_ENDPOINT = "https://s3.ru1.storage.beget.cloud"
S3_ACCESS_KEY = "RECD00AQJIM4300MLJ0W"
S3_SECRET_KEY = "FIucJ3i9iIWZ5ieJvabvI0OxEn2Yv4gG5XRUeSNf"
S3_BUCKET = "73d16f7545b3-promogoods"
S3_REGION = "ru1"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∂–∞—Ç–∏—è
MAX_DIMENSION = 1920  # –º–∞–∫—Å —Ä–∞–∑–º–µ—Ä –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
WEBP_QUALITY = 85     # –∫–∞—á–µ—Å—Ç–≤–æ WebP (0-100)
MIN_SIZE_MB = 1.0     # —Å–∂–∏–º–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã > 1 MB
BATCH_SIZE = 50       # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º

def init_s3():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è S3 –∫–ª–∏–µ–Ω—Ç–∞"""
    return boto3.client(
        's3',
        endpoint_url=S3_ENDPOINT,
        aws_access_key_id=S3_ACCESS_KEY,
        aws_secret_access_key=S3_SECRET_KEY,
        region_name=S3_REGION,
        config=Config(signature_version='s3v4')
    )

def download_image(url):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL"""
    response = requests.get(url, timeout=30)
    response.raise_for_status()
    return Image.open(BytesIO(response.content))

def compress_image(img):
    """
    –°–∂–∞—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
    1. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –¥–æ MAX_DIMENSION –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
    2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WebP —Å –∫–∞—á–µ—Å—Ç–≤–æ–º WEBP_QUALITY
    """
    original_size = img.size
    
    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –µ—Å–ª–∏ –±–æ–ª—å—à–µ MAX_DIMENSION
    width, height = img.size
    max_side = max(width, height)
    
    resized = False
    if max_side > MAX_DIMENSION:
        scale = MAX_DIMENSION / max_side
        new_width = int(width * scale)
        new_height = int(height * scale)
        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        resized = True
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –µ—Å—Ç—å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª
    if img.mode in ('RGBA', 'LA', 'P'):
        background = Image.new('RGB', img.size, (255, 255, 255))
        if img.mode == 'P':
            img = img.convert('RGBA')
        background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
        img = background
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ WebP
    output = BytesIO()
    img.save(output, format='WebP', quality=WEBP_QUALITY, method=6)
    output.seek(0)
    
    return output, original_size, img.size, resized

def upload_to_s3(s3_client, file_data, s3_key):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ S3"""
    file_data.seek(0)  # –í–∞–∂–Ω–æ: —Å–±—Ä–æ—Å –ø–æ–∑–∏—Ü–∏–∏ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
    s3_client.upload_fileobj(
        file_data,
        S3_BUCKET,
        s3_key,
        ExtraArgs={'ContentType': 'image/webp'}
    )

def process_all_images():
    """
    –ú–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    log_file = Path("compression_log.txt")
    
    print(f"\n{'='*80}")
    print(f"üñºÔ∏è  –ú–ê–°–°–û–í–û–ï –°–ñ–ê–¢–ò–ï –ë–û–õ–¨–®–ò–• –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print(f"{'='*80}")
    print(f"–†–µ–∂–∏–º: –ü–†–û–î–ê–ö–®–ù")
    print(f"–ú–∏–Ω. —Ä–∞–∑–º–µ—Ä: {MIN_SIZE_MB} MB")
    print(f"–ú–∞–∫—Å. —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {MAX_DIMENSION}px")
    print(f"–ö–∞—á–µ—Å—Ç–≤–æ WebP: {WEBP_QUALITY}")
    print(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {BATCH_SIZE}")
    print(f"–õ–æ–≥: {log_file}")
    print(f"{'='*80}\n")
    
    db = PostgreSQLManager()
    s3 = init_s3()
    
    start_time = datetime.now()
    
    with db.get_session() as session:
        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±—É–¥–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Ä–∞–∑–º–µ—Ä—É –Ω–∞ –ª–µ—Ç—É)
        total_images = session.execute(
            text("""
                SELECT COUNT(*)
                FROM product_images
                WHERE image_url IS NOT NULL
                AND image_filename NOT LIKE '%.webp'
            """)
        ).scalar()
        
        print(f"üìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ë–î (–Ω–µ WebP): {total_images:,}\n")
        print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ —Å–∂–∞—Ç–∏–µ...\n")
        
        processed = 0
        skipped_small = 0
        skipped_webp = 0
        errors = 0
        total_saved_mb = 0
        batch_updates = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Ä—Ü–∏—è–º–∏
        offset = 0
        chunk_size = 100
        
        with open(log_file, 'w', encoding='utf-8') as log:
            log.write(f"Compression Log - {datetime.now()}\n")
            log.write(f"{'='*80}\n\n")
            
            while True:
                # –ü–æ–ª—É—á–∞–µ–º –æ—á–µ—Ä–µ–¥–Ω—É—é –ø–æ—Ä—Ü–∏—é
                images = session.execute(
                    text("""
                        SELECT 
                            pi.id,
                            pi.image_url,
                            pi.image_filename,
                            pi.product_id
                        FROM product_images pi
                        WHERE pi.image_url IS NOT NULL
                        AND pi.image_filename NOT LIKE '%.webp'
                        ORDER BY pi.id
                        LIMIT :chunk_size OFFSET :offset
                    """),
                    {'chunk_size': chunk_size, 'offset': offset}
                ).fetchall()
                
                if not images:
                    break
                
                for img_id, url, filename, product_id in images:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                        head_response = requests.head(url, timeout=5)
                        if head_response.status_code != 200:
                            errors += 1
                            log.write(f"ERROR: {filename} - File not accessible\n")
                            continue
                        
                        original_size = int(head_response.headers.get('Content-Length', 0))
                        original_size_mb = original_size / 1024 / 1024
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —Ñ–∞–π–ª—ã
                        if original_size_mb < MIN_SIZE_MB:
                            skipped_small += 1
                            continue
                        
                        # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Å–∂–∏–º–∞–µ–º
                        img = download_image(url)
                        compressed, orig_size, new_size, was_resized = compress_image(img)
                        compressed_size = len(compressed.getvalue())
                        compressed_size_mb = compressed_size / 1024 / 1024
                        
                        # –ù–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (.webp)
                        new_filename = filename.rsplit('.', 1)[0] + '.webp'
                        s3_key = f"images/{new_filename}"
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ S3
                        upload_to_s3(s3, compressed, s3_key)
                        new_url = f"{S3_ENDPOINT}/{S3_BUCKET}/{s3_key}"
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞—Ç—á –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                        batch_updates.append({
                            'img_id': img_id,
                            'new_filename': new_filename,
                            'new_url': new_url
                        })
                        
                        # –ö–æ–º–º–∏—Ç–∏–º –±–∞—Ç—á –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ —Ä–∞–∑–º–µ—Ä–∞
                        if len(batch_updates) >= BATCH_SIZE:
                            for upd in batch_updates:
                                session.execute(
                                    text("""
                                        UPDATE product_images
                                        SET 
                                            image_filename = :new_filename,
                                            image_url = :new_url
                                        WHERE id = :img_id
                                    """),
                                    upd
                                )
                            session.commit()
                            batch_updates = []
                        
                        saved_mb = original_size_mb - compressed_size_mb
                        total_saved_mb += saved_mb
                        processed += 1
                        
                        # –ü—Ä–æ–≥—Ä–µ—Å—Å
                        elapsed = (datetime.now() - start_time).total_seconds()
                        speed = processed / elapsed if elapsed > 0 else 0
                        
                        status = f"‚úÖ [{processed}] {filename}"
                        if was_resized:
                            status += f" {orig_size[0]}x{orig_size[1]}‚Üí{new_size[0]}x{new_size[1]}"
                        status += f" | {original_size_mb:.2f}MB ‚Üí {compressed_size_mb:.2f}MB ({compressed_size_mb/original_size_mb*100:.1f}%) | Œ£={total_saved_mb:.1f}MB | {speed:.1f}img/s"
                        
                        print(status)
                        log.write(status + '\n')
                        
                        # –ü–∞—É–∑–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å S3
                        if processed % 10 == 0:
                            time.sleep(0.5)
                        
                    except Exception as e:
                        errors += 1
                        error_msg = f"‚ùå ERROR: {filename} - {str(e)}"
                        print(error_msg)
                        log.write(error_msg + '\n')
                        continue
                
                offset += chunk_size
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
                if offset % 1000 == 0:
                    print(f"\nüìä –ü—Ä–æ–≥—Ä–µ—Å—Å: –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {offset}/{total_images:,} ({offset/total_images*100:.1f}%)")
                    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed} | –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_small} | –û—à–∏–±–æ–∫: {errors}\n")
            
            # –ö–æ–º–º–∏—Ç–∏–º –æ—Å—Ç–∞—Ç–æ–∫ –±–∞—Ç—á–∞
            if batch_updates:
                for upd in batch_updates:
                    session.execute(
                        text("""
                            UPDATE product_images
                            SET 
                                image_filename = :new_filename,
                                image_url = :new_url
                            WHERE id = :img_id
                        """),
                        upd
                    )
                session.commit()
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_time = (datetime.now() - start_time).total_seconds()
            
            summary = f"""
{'='*80}
‚úÖ –ó–ê–í–ï–†–®–ï–ù–û
{'='*80}
–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed:,}
–ü—Ä–æ–ø—É—â–µ–Ω–æ (–º–∞–ª–µ–Ω—å–∫–∏–µ): {skipped_small:,}
–û—à–∏–±–æ–∫: {errors:,}
–û–±—â–∞—è —ç–∫–æ–Ω–æ–º–∏—è: {total_saved_mb:.2f} MB ({total_saved_mb/1024:.2f} GB)
–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {int(total_time//60)}–º {int(total_time%60)}—Å
–°–∫–æ—Ä–æ—Å—Ç—å: {processed/total_time:.2f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫
{'='*80}
"""
            print(summary)
            log.write(summary)

if __name__ == '__main__':
    try:
        process_all_images()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\n")
    except Exception as e:
        print(f"\n\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}\n")
        import traceback
        traceback.print_exc()

