#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
–ù–∞—Ö–æ–¥–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –∏ —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏.
"""

import os
import hashlib
from pathlib import Path
from collections import defaultdict
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(str(Path(__file__).parent.parent))

from database import db_manager, image_service
from loguru import logger

class ImageDuplicateRemover:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.images_dir = Path(__file__).parent.parent / "storage" / "images"
        self.logger = logger
        
    def calculate_file_hash(self, file_path: Path) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö–µ—à —Ñ–∞–π–ª–∞"""
        if not file_path.exists():
            return ""
            
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return ""
    
    def find_duplicate_images(self):
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        self.logger.info("üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ë–î
        all_images = image_service.get_all_images()
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ë–î")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ö–µ—à—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        hash_groups = defaultdict(list)
        missing_files = []
        
        for image in all_images:
            file_path = Path(image.local_path)
            
            if not file_path.exists():
                missing_files.append(image)
                continue
                
            file_hash = self.calculate_file_hash(file_path)
            if file_hash:
                hash_groups[file_hash].append(image)
        
        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä—É–ø–ø—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        duplicates = {hash_val: images for hash_val, images in hash_groups.items() if len(images) > 1}
        
        self.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        self.logger.info(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(hash_groups)}")
        self.logger.info(f"  ‚Ä¢ –ì—Ä—É–ø–ø —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {len(duplicates)}")
        self.logger.info(f"  ‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(missing_files)}")
        
        total_duplicates = sum(len(images) - 1 for images in duplicates.values())
        self.logger.info(f"  ‚Ä¢ –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫ —É–¥–∞–ª–µ–Ω–∏—é: {total_duplicates}")
        
        return duplicates, missing_files
    
    def remove_duplicates(self, duplicates: dict, dry_run: bool = True):
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Å–∞–º–æ–µ —Ä–∞–Ω–Ω–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
        removed_count = 0
        freed_space = 0
        
        for file_hash, images in duplicates.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ID (—Å–∞–º–æ–µ —Ä–∞–Ω–Ω–µ–µ - —Å –º–µ–Ω—å—à–∏–º ID)
            images.sort(key=lambda x: x.id)
            keep_image = images[0]  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤–æ–µ (—Å–∞–º–æ–µ —Ä–∞–Ω–Ω–µ–µ)
            remove_images = images[1:]  # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
            
            self.logger.info(f"\nüìÅ –ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (hash: {file_hash[:8]}...):")
            self.logger.info(f"  ‚úÖ –û—Å—Ç–∞–≤–ª—è–µ–º: {keep_image.image_filename} (ID: {keep_image.id})")
            
            for image in remove_images:
                file_path = Path(image.local_path)
                file_size = file_path.stat().st_size if file_path.exists() else 0
                
                self.logger.info(f"  üóëÔ∏è  –£–¥–∞–ª—è–µ–º: {image.image_filename} (ID: {image.id}) - {file_size} –±–∞–π—Ç")
                
                if not dry_run:
                    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
                    if file_path.exists():
                        file_path.unlink()
                        freed_space += file_size
                    
                    # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å –∏–∑ –ë–î
                    with db_manager.get_session() as session:
                        session.delete(session.merge(image))
                        session.commit()
                
                removed_count += 1
        
        if dry_run:
            self.logger.info(f"\nüîç –†–ï–ñ–ò–ú –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–û–ì–û –ü–†–û–°–ú–û–¢–†–ê")
            self.logger.info(f"üìä –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ: {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            self.logger.info(f"üíæ –ë—É–¥–µ—Ç –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {freed_space / 1024:.1f} KB")
            self.logger.info(f"‚ñ∂Ô∏è  –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º --execute")
        else:
            self.logger.info(f"\n‚úÖ –£–î–ê–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
            self.logger.info(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {removed_count}")
            self.logger.info(f"üíæ –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ –º–µ—Å—Ç–∞: {freed_space / 1024:.1f} KB")
    
    def remove_missing_files(self, missing_files: list, dry_run: bool = True):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ –æ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–∞—Ö"""
        if not missing_files:
            return
            
        self.logger.info(f"\nüîç –ù–∞–π–¥–µ–Ω–æ {len(missing_files)} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏:")
        
        for image in missing_files:
            self.logger.info(f"  üóëÔ∏è  {image.image_filename} (ID: {image.id}) - —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            if not dry_run:
                with db_manager.get_session() as session:
                    session.delete(session.merge(image))
                    session.commit()
        
        if not dry_run:
            self.logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {len(missing_files)} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    parser.add_argument("--execute", action="store_true", 
                       help="–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä)")
    parser.add_argument("--remove-missing", action="store_true",
                       help="–¢–∞–∫–∂–µ —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏")
    
    args = parser.parse_args()
    
    remover = ImageDuplicateRemover()
    
    # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates, missing_files = remover.find_duplicate_images()
    
    if not duplicates and not missing_files:
        logger.info("‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    if duplicates:
        remover.remove_duplicates(duplicates, dry_run=not args.execute)
    
    # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
    if missing_files and args.remove_missing:
        remover.remove_missing_files(missing_files, dry_run=not args.execute)
    
    if not args.execute:
        logger.info(f"\nüí° –î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
        logger.info(f"   python cleanup_duplicate_images.py --execute")
        if missing_files:
            logger.info(f"   python cleanup_duplicate_images.py --execute --remove-missing")


if __name__ == "__main__":
    main()


