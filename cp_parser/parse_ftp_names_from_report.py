#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–∏–Ω–≥ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ—Ç—á–µ—Ç–∞ STORAGE_ANALYSIS –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
"""

import re
import csv

def parse_filename(filename):
    """
    –ü–∞—Ä—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    
    –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
    1. {sheet_id}_{position}_{hash}.png
       –ü—Ä–∏–º–µ—Ä: 1fwvX9lN3tRlhmI_X0Ie9b-W1wX8B-2sh-vDSfc9NdbY_O4_04a64599.png
       
    2. {sheet_id}_{position}_{suffix}_{hash}.png
       –ü—Ä–∏–º–µ—Ä: 16t27DZ6EnQVx7DeHN9F1GKr4Ae9o5KL9luBS_rQ8WKg_Q8_3_62b0f70c.png
       
    3. {sheet_id}_{position}_{suffix}_{additional_hash}.png
       –ü—Ä–∏–º–µ—Ä: 1dsi__IfdxC-e1mhEGTWC72M0LLu8ZDaTQ2pcssebdI8_J3_1_acecbcc28340b119.png
    """
    
    if not filename.endswith('.png'):
        return None
    
    # –£–±–∏—Ä–∞–µ–º .png –∏ –≤–æ–∑–º–æ–∂–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ
    name = filename
    if name.endswith('...'):
        # –§–∞–π–ª –±—ã–ª –æ–±—Ä–µ–∑–∞–Ω –≤ –æ—Ç—á–µ—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        return None
    
    name = name.replace('.png', '').replace('.pn', '').replace('.p', '')
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—é
    parts = name.split('_')
    
    if len(parts) < 3:
        return None
    
    result = {
        'filename': filename,
        'sheet_id': None,
        'position': None,
        'suffix': None,
        'hash': None
    }
    
    # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é (–±—É–∫–≤–∞/–±—É–∫–≤—ã + —Ü–∏—Ñ—Ä—ã)
    position_pattern = r'^[A-Z]+\d+$'
    
    for i in range(1, len(parts)):
        if re.match(position_pattern, parts[i]):
            # –ù–∞—à–ª–∏ –ø–æ–∑–∏—Ü–∏—é
            result['sheet_id'] = '_'.join(parts[:i])
            result['position'] = parts[i]
            
            # –û—Å—Ç–∞–ª—å–Ω–æ–µ - —Å—É—Ñ—Ñ–∏–∫—Å –∏/–∏–ª–∏ —Ö–µ—à
            remaining = parts[i+1:]
            
            if len(remaining) == 1:
                # –¢–æ–ª—å–∫–æ —Ö–µ—à
                result['hash'] = remaining[0]
            elif len(remaining) == 2:
                # –°—É—Ñ—Ñ–∏–∫—Å –∏ —Ö–µ—à (–∏–ª–∏ –¥–≤–∞ —Ö–µ—à–∞)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º - –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π (1-2 —Å–∏–º–≤–æ–ª–∞), —ç—Ç–æ —Å—É—Ñ—Ñ–∏–∫—Å
                if len(remaining[0]) <= 3 and remaining[0].isdigit():
                    result['suffix'] = remaining[0]
                    result['hash'] = remaining[1]
                else:
                    # –û–±–∞ —Ö–µ—à–∞
                    result['hash'] = '_'.join(remaining)
            elif len(remaining) > 2:
                # –°—É—Ñ—Ñ–∏–∫—Å + —Å–æ—Å—Ç–∞–≤–Ω–æ–π —Ö–µ—à
                if len(remaining[0]) <= 3 and remaining[0].isdigit():
                    result['suffix'] = remaining[0]
                    result['hash'] = '_'.join(remaining[1:])
                else:
                    result['hash'] = '_'.join(remaining)
            
            break
    
    return result if result['sheet_id'] and result['position'] else None


def extract_filenames_from_report(report_file):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ—Ç—á–µ—Ç–∞"""
    filenames = []
    
    with open(report_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–∞–∑–º–µ—Ä–æ–º —Ñ–∞–π–ª–∞ –∏ –∏–º–µ–Ω–µ–º
            # –§–æ—Ä–º–∞—Ç: "   SIZE - FILENAME"
            # –ü—Ä–∏–º–µ—Ä: "   10.97 MB - 17Y5ilb95T7UPkRIOHcFajqKJS-Hi824gkeGKGjQq6m4_N31_088583bc.png"
            
            match = re.search(r'\d+\.\d+\s+(KB|MB|GB)\s+-\s+(.+)$', line)
            if match:
                filename = match.group(2).strip()
                filenames.append(filename)
    
    return filenames


def main():
    print("=" * 80)
    print("üìä –ü–ê–†–°–ò–ù–ì –ò–ú–ï–ù –§–ê–ô–õ–û–í –ò–ó –û–¢–ß–ï–¢–ê")
    print("=" * 80)
    print()
    
    report_file = 'STORAGE_ANALYSIS_20251012_1455.txt'
    
    print(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {report_file}")
    filenames = extract_filenames_from_report(report_file)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(filenames):,} —Ñ–∞–π–ª–æ–≤")
    
    print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤...")
    
    results = []
    failed = []
    skipped_truncated = 0
    
    for i, filename in enumerate(filenames, 1):
        if i % 1000 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,} / {len(filenames):,} ({i/len(filenames)*100:.1f}%)")
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
        if '...' in filename:
            skipped_truncated += 1
            continue
        
        parsed = parse_filename(filename)
        
        if parsed:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL
            full_url = f"https://ftp.ru1.storage.beget.cloud/73d16f7545b3-promogoods/images/{filename}"
            
            results.append({
                'image_url': full_url,
                'sheet_id': parsed['sheet_id'],
                'position': parsed['position'],
                'suffix': parsed['suffix'] or '',
                'hash': parsed['hash'],
                'filename': filename
            })
        else:
            failed.append(filename)
    
    print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ: {len(results):,}")
    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö: {skipped_truncated:,}")
    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {len(failed):,}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV
    csv_file = 'FTP_FILES_ANALYSIS.csv'
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤ {csv_file}...")
    
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['image_url', 'sheet_id', 'position', 'suffix'])
        writer.writeheader()
        
        for row in results:
            writer.writerow({
                'image_url': row['image_url'],
                'sheet_id': row['sheet_id'],
                'position': row['position'],
                'suffix': row['suffix']
            })
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(results):,} –∑–∞–ø–∏—Å–µ–π")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ sheet_id
    sheets = {}
    for row in results:
        sid = row['sheet_id']
        if sid not in sheets:
            sheets[sid] = []
        sheets[sid].append(row)
    
    print(f"\nüìÅ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü: {len(sheets):,}")
    
    # –§–∞–π–ª—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ (–¥—É–±–ª–∏)
    with_suffix = [r for r in results if r['suffix']]
    print(f"üîÑ –§–∞–π–ª–æ–≤ —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥—É–±–ª–∏): {len(with_suffix):,}")
    
    # –¢–û–ü-10 —Ç–∞–±–ª–∏—Ü –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    print(f"\nüîù –¢–û–ü-10 —Ç–∞–±–ª–∏—Ü –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
    top_sheets = sorted(sheets.items(), key=lambda x: len(x[1]), reverse=True)[:10]
    for i, (sheet_id, files) in enumerate(top_sheets, 1):
        suffix_count = len([f for f in files if f['suffix']])
        print(f"   {i:2d}. {sheet_id[:50]:50s} - {len(files):4d} —Ñ–∞–π–ª–æ–≤ ({suffix_count} —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏)")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
    positions = {}
    for row in results:
        pos = row['position']
        if pos not in positions:
            positions[pos] = 0
        positions[pos] += 1
    
    print(f"\nüìç –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π: {len(positions):,}")
    print(f"\nüîù –¢–û–ü-10 –ø–æ–∑–∏—Ü–∏–π:")
    top_positions = sorted(positions.items(), key=lambda x: x[1], reverse=True)[:10]
    for i, (pos, count) in enumerate(top_positions, 1):
        print(f"   {i:2d}. {pos:4s} - {count:5d} —Ñ–∞–π–ª–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ
    if failed:
        failed_file = 'FTP_FAILED_PARSING.txt'
        print(f"\n‚ö†Ô∏è  –°–æ—Ö—Ä–∞–Ω—è—é –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ {failed_file}...")
        with open(failed_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(failed))
        print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(failed)} —Ñ–∞–π–ª–æ–≤")
    
    # –ü—Ä–∏–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏
    if with_suffix:
        print(f"\nüìã –ü–†–ò–ú–ï–†–´ –§–ê–ô–õ–û–í –° –°–£–§–§–ò–ö–°–ê–ú–ò (–ø–µ—Ä–≤—ã–µ 10):")
        for i, row in enumerate(with_suffix[:10], 1):
            print(f"   {i:2d}. Sheet: {row['sheet_id'][:40]:40s} | Pos: {row['position']:4s} | Suffix: {row['suffix']}")
    
    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 80)
    print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {csv_file}")
    print(f"üìä –§–æ—Ä–º–∞—Ç: image_url | sheet_id | position | suffix")
    print(f"\nüí° –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç CSV –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –ë–î –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è:")
    print(f"   ‚Ä¢ –î—É–±–ª–µ–π (—Ñ–∞–π–ª—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º sheet_id + position –Ω–æ —Ä–∞–∑–Ω—ã–º–∏ —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏)")
    print(f"   ‚Ä¢ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤ –ë–î")
    print(f"   ‚Ä¢ –õ–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ –Ω–∞ FTP")


if __name__ == '__main__':
    main()

