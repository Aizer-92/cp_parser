#!/usr/bin/env python3
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π - –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π URL –∏–∑ –¥—É–±–ª–µ–π
"""

import csv

def process_multiple_matches(input_file, output_file):
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π URL –∏–∑ —Å–ø–∏—Å–∫–∞ –¥—É–±–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    print(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {input_file}")
    
    resolved = []
    
    with open(input_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π URL –∏–∑ —Å–ø–∏—Å–∫–∞
            urls = row['ftp_urls'].split(' | ')
            first_url = urls[0]
            
            resolved.append({
                'image_id': row['image_id'],
                'product_id': row['product_id'],
                'sheet_id': row['sheet_id'],
                'position': row['position'],
                'image_type': row['image_type'],
                'row_number': row['row_number'],
                'product_name': row['product_name'],
                'ftp_url': first_url,
                'match_type': 'multiple_resolved',
                'total_duplicates': row['urls_count']
            })
    
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(resolved):,} –∑–∞–ø–∏—Å–µ–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤ {output_file}...")
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'image_id', 'product_id', 'sheet_id', 'position', 
            'image_type', 'row_number', 'product_name', 
            'ftp_url', 'match_type', 'total_duplicates'
        ])
        writer.writeheader()
        writer.writerows(resolved)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(resolved):,} –∑–∞–ø–∏—Å–µ–π")
    return resolved


def main():
    print("=" * 80)
    print("üîç –û–ë–†–ê–ë–û–¢–ö–ê –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–• –°–û–í–ü–ê–î–ï–ù–ò–ô")
    print("=" * 80)
    print()
    
    print("üí° –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π URL –∏–∑ —Å–ø–∏—Å–∫–∞ –¥—É–±–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    print()
    
    resolved = process_multiple_matches(
        'IMAGES_MULTIPLE_MATCHES.csv',
        'IMAGES_MULTIPLE_RESOLVED.csv'
    )
    
    print("\n" + "=" * 80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(resolved):,}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥—É–±–ª–µ–π
    duplicate_counts = {}
    for item in resolved:
        count = item['total_duplicates']
        if count not in duplicate_counts:
            duplicate_counts[count] = 0
        duplicate_counts[count] += 1
    
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥—É–±–ª–µ–π:")
    for count in sorted(duplicate_counts.keys(), key=lambda x: int(x), reverse=True)[:10]:
        print(f"   {count} –¥—É–±–ª–µ–π: {duplicate_counts[count]:,} –∑–∞–ø–∏—Å–µ–π")
    
    print("\n‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç: IMAGES_MULTIPLE_RESOLVED.csv")
    print(f"üí° –≠—Ç–æ—Ç —Ñ–∞–π–ª –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è UPDATE –≤–º–µ—Å—Ç–µ —Å IMAGES_TO_UPDATE_URL.csv")


if __name__ == '__main__':
    main()

