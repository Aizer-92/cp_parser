#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤–æ–µ —Å–∂–∞—Ç–∏–µ 20 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""

import os
import csv
import re
from ftplib import FTP_TLS
from PIL import Image
import io
import time

# FTP –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
FTP_HOST = "ftp.ru1.storage.beget.cloud"
FTP_USER = "RECD00AQJIM4300MLJ0W"
FTP_PASS = "FIucJ3i9iIWZ5ieJvabvI0OxEn2Yv4gG5XRUeSNf"
FTP_DIR = "/73d16f7545b3-promogoods/images"

def get_top_20_largest_files():
    """–ü–æ–ª—É—á–∏—Ç—å 20 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""
    print("üìÑ –ß–∏—Ç–∞—é —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤...")
    
    files = []
    with open('STORAGE_ANALYSIS_20251012_1455.txt', 'r', encoding='utf-8') as f:
        count = 0
        for line in f:
            line = line.strip()
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏ (—Ñ–æ—Ä–º–∞—Ç: "    1.   10.97 MB - filename.png")
            if 'MB -' in line and '.png' in line:
                try:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ " - "
                    parts = line.split(' - ', 1)
                    if len(parts) == 2:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä
                        size_part = parts[0].strip()
                        # –ò—â–µ–º —Ä–∞–∑–º–µ—Ä –≤ MB
                        size_match = re.search(r'(\d+\.\d+)\s+MB', size_part)
                        if size_match:
                            size_mb = float(size_match.group(1))
                            filename = parts[1].strip()
                            
                            # –£–±–∏—Ä–∞–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –∏ –Ω–µ-png —Ñ–∞–π–ª—ã
                            if filename.endswith('.png') and not filename.endswith('...'):
                                files.append({
                                    'filename': filename,
                                    'size_mb': size_mb
                                })
                                count += 1
                                
                                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ 20 —Ñ–∞–π–ª–æ–≤
                                if count >= 20:
                                    break
                except:
                    continue
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    return files


def download_and_compress_file(ftp, filename, original_size_mb):
    """–°–∫–∞—á–∞—Ç—å, —Å–∂–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ —Ñ–∞–π–ª"""
    print(f"\nüì• –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {filename[:60]}...")
    print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {original_size_mb:.2f} MB")
    
    try:
        # 1. –°–∫–∞—á–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        original_data = io.BytesIO()
        ftp.retrbinary(f'RETR {filename}', original_data.write)
        original_data.seek(0)
        original_size_kb = len(original_data.getvalue()) / 1024
        
        # 2. –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.open(original_data)
        original_format = img.format
        original_dimensions = img.size
        
        print(f"   –§–æ—Ä–º–∞—Ç: {original_format}, –†–∞–∑–º–µ—Ä: {original_dimensions[0]}x{original_dimensions[1]}")
        
        # 3. –†–µ—Å–∞–π–∑ –¥–æ 1920px –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
        max_size = 1920
        if max(original_dimensions) > max_size:
            # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            if original_dimensions[0] > original_dimensions[1]:
                # –®–∏—Ä–∏–Ω–∞ –±–æ–ª—å—à–µ
                new_width = max_size
                new_height = int(original_dimensions[1] * (max_size / original_dimensions[0]))
            else:
                # –í—ã—Å–æ—Ç–∞ –±–æ–ª—å—à–µ
                new_height = max_size
                new_width = int(original_dimensions[0] * (max_size / original_dimensions[1]))
            
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            resized_dimensions = (new_width, new_height)
            print(f"   –†–µ—Å–∞–π–∑: {original_dimensions[0]}x{original_dimensions[1]} ‚Üí {new_width}x{new_height}")
        else:
            resized_dimensions = original_dimensions
        
        # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        # 5. –°–∂–∏–º–∞–µ–º –≤ WebP
        compressed_data = io.BytesIO()
        img.save(compressed_data, format='WEBP', quality=85, method=6)
        compressed_data.seek(0)
        compressed_size_kb = len(compressed_data.getvalue()) / 1024
        
        # 5. –°–æ–∑–¥–∞–µ–º –∏–º—è –¥–ª—è —Å–∂–∞—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        compressed_filename = filename.replace('.png', '_compressed.webp')
        
        # 6. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∂–∞—Ç—ã–π —Ñ–∞–π–ª –Ω–∞ FTP
        compressed_data.seek(0)
        ftp.storbinary(f'STOR {compressed_filename}', compressed_data)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        compression_ratio = (1 - compressed_size_kb / original_size_kb) * 100
        
        print(f"   ‚úÖ –°–∂–∞—Ç–æ: {compressed_size_kb:.2f} KB")
        print(f"   üíæ –≠–∫–æ–Ω–æ–º–∏—è: {compression_ratio:.1f}%")
        
        return {
            'filename': filename,
            'compressed_filename': compressed_filename,
            'original_size_kb': original_size_kb,
            'compressed_size_kb': compressed_size_kb,
            'compression_ratio': compression_ratio,
            'original_dimensions': f"{original_dimensions[0]}x{original_dimensions[1]}",
            'resized_dimensions': f"{resized_dimensions[0]}x{resized_dimensions[1]}",
            'original_url': f"https://ftp.ru1.storage.beget.cloud{FTP_DIR}/{filename}",
            'compressed_url': f"https://ftp.ru1.storage.beget.cloud{FTP_DIR}/{compressed_filename}"
        }
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
        return None


def main():
    print("=" * 80)
    print("üß™ –¢–ï–°–¢–û–í–û–ï –°–ñ–ê–¢–ò–ï 20 –°–ê–ú–´–• –ë–û–õ–¨–®–ò–• –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô")
    print("=" * 80)
    print()
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
    files = get_top_20_largest_files()
    
    if not files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–∂–∞—Ç–∏—è")
        return
    
    # 2. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ FTP
    print(f"\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ FTP...")
    print(f"   Host: {FTP_HOST}")
    print(f"   Path: {FTP_DIR}")
    
    ftp = FTP_TLS(FTP_HOST)
    ftp.login(FTP_USER, FTP_PASS)
    ftp.prot_p()
    ftp.cwd(FTP_DIR)
    
    print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ")
    
    # 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
    results = []
    
    for i, file_info in enumerate(files, 1):
        print(f"\n{'=' * 80}")
        print(f"üìä –§–∞–π–ª {i}/{len(files)}")
        
        result = download_and_compress_file(
            ftp, 
            file_info['filename'], 
            file_info['size_mb']
        )
        
        if result:
            results.append(result)
        
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
        time.sleep(0.5)
    
    ftp.quit()
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 80)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–û–í–û–ì–û –°–ñ–ê–¢–ò–Ø")
    print("=" * 80)
    
    if not results:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    csv_file = 'TEST_COMPRESSION_RESULTS.csv'
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {csv_file}...")
    
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'filename', 'compressed_filename', 
            'original_size_kb', 'compressed_size_kb', 
            'compression_ratio', 'original_dimensions', 'resized_dimensions',
            'original_url', 'compressed_url'
        ])
        writer.writeheader()
        writer.writerows(results)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_original = sum(r['original_size_kb'] for r in results) / 1024
    total_compressed = sum(r['compressed_size_kb'] for r in results) / 1024
    total_saved = total_original - total_compressed
    avg_compression = sum(r['compression_ratio'] for r in results) / len(results)
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")
    print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {total_original:.2f} MB")
    print(f"   –°–∂–∞—Ç—ã–π —Ä–∞–∑–º–µ—Ä: {total_compressed:.2f} MB")
    print(f"   –≠–∫–æ–Ω–æ–º–∏—è: {total_saved:.2f} MB ({avg_compression:.1f}%)")
    
    # –°—Å—ã–ª–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    print("\n" + "=" * 80)
    print("üîó –°–°–´–õ–ö–ò –î–õ–Ø –ü–†–û–í–ï–†–ö–ò")
    print("=" * 80)
    
    print("\nüìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª vs —Å–∂–∞—Ç—ã–π:\n")
    
    for i, result in enumerate(results[:5], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
        print(f"{i}. {result['filename'][:60]}")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª:  {result['original_url']}")
        print(f"   –°–∂–∞—Ç—ã–π:    {result['compressed_url']}")
        print(f"   –†–∞–∑–º–µ—Ä—ã:   {result['original_dimensions']} ‚Üí {result['resized_dimensions']}")
        print(f"   –≠–∫–æ–Ω–æ–º–∏—è:  {result['compression_ratio']:.1f}%")
        print()
    
    if len(results) > 5:
        print(f"... –∏ –µ—â–µ {len(results) - 5} —Ñ–∞–π–ª–æ–≤ (—Å–º. {csv_file})")
    
    print("\n" + "=" * 80)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)
    print(f"\nüí° –ü—Ä–æ–≤–µ—Ä—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–∂–∞—Ç—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Å—Å—ã–ª–∫–∞–º –≤—ã—à–µ")
    print(f"üìÑ –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫: {csv_file}")


if __name__ == '__main__':
    main()

