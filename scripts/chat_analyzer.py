#!/usr/bin/env python3
"""
ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ‡Ð°Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ð¸Ð· ChatGPT/Perplexity

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
    python scripts/chat_analyzer.py "Ñ‚ÐµÐºÑÑ‚ Ñ‡Ð°Ñ‚Ð°"
    python scripts/chat_analyzer.py --file "Ð¿ÑƒÑ‚ÑŒ_Ðº_Ñ„Ð°Ð¹Ð»Ñƒ.txt"
"""

import argparse
import re
import json
from datetime import datetime
from pathlib import Path

# ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
CATEGORY_KEYWORDS = {
    'Business': [
        'startup', 'business', 'Ð¿Ñ€ÐµÐ´Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð¾', 'Ð±Ð¸Ð·Ð½ÐµÑ', 'ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ', 'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ',
        'Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³', 'Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸', 'ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹', 'revenue', 'profit', 'ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ñ‹',
        'scaling', 'growth', 'venture', 'investment round', 'pitch', 'business plan'
    ],
    'Health': [
        'Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ', 'health', 'Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½Ð°', 'nutrition', 'Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ðµ', 'Ð´Ð¸ÐµÑ‚Ð°', 'fitness',
        'Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²ÐºÐ°', 'exercise', 'weight', 'Ð²ÐµÑ', 'Ð±Ð¾Ð»ÐµÐ·Ð½ÑŒ', 'ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹', 'Ð²Ñ€Ð°Ñ‡',
        'Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ', 'Ð¿Ñ€ÐµÐ¿Ð°Ñ€Ð°Ñ‚', 'Ð²Ð¸Ñ‚Ð°Ð¼Ð¸Ð½Ñ‹', 'wellness', 'mental health', 'Ð°Ð½Ð°Ð»Ð¸Ð·Ñ‹',
        'Ñ‚ÐµÑÑ‚Ð¾ÑÑ‚ÐµÑ€Ð¾Ð½', 'testosterone', 'Ð³Ð¾Ñ€Ð¼Ð¾Ð½Ñ‹', 'hormones', 'ÑÑÑ‚Ñ€Ð°Ð´Ð¸Ð¾Ð»', 'estradiol',
        'Ñ„ÑÐ³', 'fsh', 'Ð»Ð³', 'lh', 'Ð³ÑÐ¿Ð³', 'shbg', 'ÑÐ½Ð´Ð¾ÐºÑ€Ð¸Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'endocrinology'
    ],
    'Finance': [
        'Ñ„Ð¸Ð½Ð°Ð½ÑÑ‹', 'finance', 'Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸', 'investment', 'Ð°ÐºÑ†Ð¸Ð¸', 'stocks', 'crypto',
        'ÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚Ð°', 'portfolio', 'Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒ', 'budget', 'Ð±ÑŽÐ´Ð¶ÐµÑ‚', 'savings',
        'Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ñ', 'debt', 'Ð´Ð¾Ð»Ð³', 'pension', 'Ð¿ÐµÐ½ÑÐ¸Ñ', 'tax', 'Ð½Ð°Ð»Ð¾Ð³Ð¸'
    ],
    'Technology': [
        'Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ', 'programming', 'python', 'javascript', 'code', 'ÐºÐ¾Ð´',
        'algorithm', 'Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼', 'API', 'database', 'frontend', 'backend',
        'AI', 'artificial intelligence', 'machine learning', 'data science'
    ],
    'Learning': [
        'Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ', 'learning', 'education', 'ÐºÑƒÑ€Ñ', 'course', 'study', 'Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ðµ',
        'Ð½Ð°Ð²Ñ‹Ðº', 'skill', 'ÑÐµÑ€Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ', 'certification', 'ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚', 'university',
        'ÐºÐ½Ð¸Ð³Ð°', 'book', 'tutorial', 'ÑƒÑ€Ð¾Ðº', 'lesson', 'knowledge'
    ],
    'Home': [
        'Ð´Ð¾Ð¼', 'home', 'Ñ€ÐµÐ¼Ð¾Ð½Ñ‚', 'renovation', 'design', 'Ð´Ð¸Ð·Ð°Ð¹Ð½', 'Ð¼ÐµÐ±ÐµÐ»ÑŒ', 'furniture',
        'ÐºÑƒÑ…Ð½Ñ', 'kitchen', 'Ð²Ð°Ð½Ð½Ð°Ñ', 'bathroom', 'garden', 'ÑÐ°Ð´', 'smart home',
        'ÑƒÐ¼Ð½Ñ‹Ð¹ Ð´Ð¾Ð¼', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚', 'project', 'DIY'
    ],
    'Work': [
        'Ñ€Ð°Ð±Ð¾Ñ‚Ð°', 'work', 'ÐºÐ°Ñ€ÑŒÐµÑ€Ð°', 'career', 'job', 'Ð´Ð¾Ð»Ð¶Ð½Ð¾ÑÑ‚ÑŒ', 'position',
        'resume', 'Ñ€ÐµÐ·ÑŽÐ¼Ðµ', 'interview', 'ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ', 'salary', 'Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°',
        'promotion', 'Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ', 'team', 'ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°', 'manager', 'Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€'
    ]
}

# Ð¢ÐµÐ³Ð¸ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ
COMMON_TAGS = {
    'startup', 'ai', 'python', 'javascript', 'react', 'health', 'fitness',
    'investment', 'crypto', 'marketing', 'design', 'productivity', 'learning',
    'testosterone', 'hormones', 'endocrinology', 'blood_test', 'medical'
}

def analyze_text_category(text):
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÑƒÑŽ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ"""
    text_lower = text.lower()
    category_scores = {}
    
    for category, keywords in CATEGORY_KEYWORDS.items():
        score = 0
        for keyword in keywords:
            # ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°
            score += len(re.findall(r'\b' + re.escape(keyword.lower()) + r'\b', text_lower))
        category_scores[category] = score
    
    # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ñ Ð½Ð°Ð¸Ð²Ñ‹ÑÑˆÐ¸Ð¼ ÑÑ‡ÐµÑ‚Ð¾Ð¼
    if max(category_scores.values()) > 0:
        return max(category_scores, key=category_scores.get)
    else:
        return 'Personal'  # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ

def extract_tags(text):
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ñ‚ÐµÐ³Ð¸ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°"""
    text_lower = text.lower()
    found_tags = []
    
    for tag in COMMON_TAGS:
        if tag in text_lower:
            found_tags.append(f'#{tag}')
    
    return found_tags[:5]  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 5 Ñ‚ÐµÐ³Ð¾Ð²

def extract_key_insights(text):
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ñ‡Ð°Ñ‚Ð°"""
    insights = []
    
    # Ð˜Ñ‰ÐµÐ¼ Ñ„Ñ€Ð°Ð·Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽÑ‚ Ð½Ð° Ð²Ñ‹Ð²Ð¾Ð´Ñ‹ Ð¸Ð»Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
    patterns = [
        r'Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ[^.]*[.]',
        r'Ð²Ð°Ð¶Ð½Ð¾[^.]*[.]',
        r'ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¹[^.]*[.]',
        r'Ð³Ð»Ð°Ð²Ð½Ð¾Ðµ[^.]*[.]',
        r'Ð²Ñ‹Ð²Ð¾Ð´[^.]*[.]',
        r'recommend[^.]*[.]',
        r'important[^.]*[.]',
        r'key[^.]*[.]',
        r'conclusion[^.]*[.]'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        insights.extend(matches[:3])  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3 Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð° Ð½Ð° Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½
    
    return insights[:5]  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 5 Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð²

def suggest_filename(text, category):
    """ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð³Ð¾"""
    today = datetime.now().strftime("%Y-%m-%d")
    
    # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ Ð¸Ð· Ð¿ÐµÑ€Ð²Ñ‹Ñ… 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
    first_part = text[:200].lower()
    
    # ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ‚ÐµÐ¼Ñ‹
    topic_keywords = {
        'Ð¿Ð»Ð°Ð½': 'Plan',
        'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ': 'Strategy', 
        'Ð°Ð½Ð°Ð»Ð¸Ð·': 'Analysis',
        'ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ': 'Creation',
        'Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°': 'Development',
        'Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ðµ': 'Learning',
        'ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ': 'Comparison',
        'Ð¿Ð»Ð°Ð½': 'Planning'
    }
    
    topic = "Discussion"
    for keyword, english in topic_keywords.items():
        if keyword in first_part:
            topic = english
            break
    
    return f"{today}_{category}_{topic}"

def create_markdown_template(text, category, tags, insights, filename):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ markdown-ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð´Ð»Ñ Ñ‡Ð°Ñ‚Ð°"""
    
    template = f"""# {filename.replace('_', ' ').replace('-', '.')}

**Ð”Ð°Ñ‚Ð°:** {datetime.now().strftime("%d.%m.%Y")}  
**Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº:** [ChatGPT/Perplexity]  
**ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ:** {category}  
**Ð¢ÐµÐ³Ð¸:** {' '.join(tags) if tags else '#Ð½Ð¾Ð²Ñ‹Ð¹_Ñ‡Ð°Ñ‚'}

## ðŸŽ¯ Ðž Ñ‡ÐµÐ¼ Ð´Ð¸Ð°Ð»Ð¾Ð³
[ÐžÐ¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÑÑƒÑ‚ÑŒ Ð¸ Ñ†ÐµÐ»ÑŒ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð°]

## ðŸ’¡ ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹
"""
    
    if insights:
        for insight in insights:
            template += f"- {insight.strip()}\n"
    else:
        template += "- [ÐšÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ 1]\n- [ÐšÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ 2]\n- [ÐšÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ 3]\n"
    
    template += """
## âœ… Ð§Ñ‚Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ
- [ ] [ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ 1]
- [ ] [ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ 2]
- [ ] [ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ 3]

---

## ðŸ’¬ Ð”Ð¸Ð°Ð»Ð¾Ð³

"""
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ°Ð¼ Ñ‚ÐµÐºÑÑ‚ Ñ‡Ð°Ñ‚Ð°
    template += text
    
    template += """

---

## ðŸ”— Ð¡Ð²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ñ‹
- [Ð¡ÑÑ‹Ð»ÐºÐ¸ Ð½Ð° ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð²Ð°ÑˆÐµÐ¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ]

## ðŸ“ ÐœÐ¾Ð¸ Ð·Ð°Ð¼ÐµÑ‚ÐºÐ¸
[Ð’Ð°ÑˆÐ¸ Ð¼Ñ‹ÑÐ»Ð¸ Ð¿Ð¾ÑÐ»Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°, Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¸Ð´ÐµÐ¸]
"""
    
    return template

def main():
    parser = argparse.ArgumentParser(description='ÐÐ½Ð°Ð»Ð¸Ð· Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð˜Ð˜-Ñ‡Ð°Ñ‚Ð¾Ð²')
    parser.add_argument('text', nargs='?', help='Ð¢ÐµÐºÑÑ‚ Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°')
    parser.add_argument('--file', help='ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ð°')
    parser.add_argument('--output', help='ÐŸÐ°Ð¿ÐºÐ° Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°')
    
    args = parser.parse_args()
    
    if args.file:
        try:
            with open(args.file, 'r', encoding='utf-8') as f:
                text = f.read()
        except FileNotFoundError:
            print(f"âŒ Ð¤Ð°Ð¹Ð» {args.file} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
            return
    elif args.text:
        text = args.text
    else:
        print("âŒ Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚ Ñ‡Ð°Ñ‚Ð° Ð¸Ð»Ð¸ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ")
        print("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ: python chat_analyzer.py 'Ñ‚ÐµÐºÑÑ‚' Ð¸Ð»Ð¸ --file file.txt")
        return
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚
    print("ðŸ” ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ‡Ð°Ñ‚...")
    category = analyze_text_category(text)
    tags = extract_tags(text)
    insights = extract_key_insights(text)
    filename = suggest_filename(text, category)
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    print(f"\nðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
    print(f"ðŸ“ ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ: {category}")
    print(f"ðŸ·ï¸  Ð¢ÐµÐ³Ð¸: {', '.join(tags) if tags else 'ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾'}")
    print(f"ðŸ’¡ Ð˜Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {len(insights)}")
    print(f"ðŸ“ ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð½Ð¾Ðµ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð°: {filename}.md")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑˆÐ°Ð±Ð»Ð¾Ð½
    markdown_content = create_markdown_template(text, category, tags, insights, filename)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ„Ð°Ð¹Ð» ÐµÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð¿Ð°Ð¿ÐºÐ° Ð²Ñ‹Ð²Ð¾Ð´Ð°
    if args.output:
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"{filename}.md"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"âœ… Ð¤Ð°Ð¹Ð» ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {output_file}")
    else:
        print(f"\nðŸ“„ Markdown ÑˆÐ°Ð±Ð»Ð¾Ð½:")
        print("=" * 50)
        print(markdown_content[:500] + "..." if len(markdown_content) > 500 else markdown_content)

if __name__ == "__main__":
    main()
